{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aleksandrmorozov123/computer-vision-with-pytorch?scriptVersionId=155174545\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-15T18:27:14.566202Z","iopub.execute_input":"2023-12-15T18:27:14.566541Z","iopub.status.idle":"2023-12-15T18:27:14.908562Z","shell.execute_reply.started":"2023-12-15T18:27:14.566513Z","shell.execute_reply":"2023-12-15T18:27:14.907626Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**Begin with foundations - tensors**","metadata":{}},{"cell_type":"code","source":"import torch\nx = torch.tensor ([[1,2,3], [4,5,6]])\ny = torch.tensor ([[7,8,9], [10,11,12]])\nz = x + y\nprint (z)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:14.910447Z","iopub.execute_input":"2023-12-15T18:27:14.910892Z","iopub.status.idle":"2023-12-15T18:27:18.441126Z","shell.execute_reply.started":"2023-12-15T18:27:14.91086Z","shell.execute_reply":"2023-12-15T18:27:18.439987Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"tensor([[ 8, 10, 12],\n        [14, 16, 18]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Create the tensors**","metadata":{}},{"cell_type":"code","source":"import numpy \n\n# created from preexisting arrays\nw = torch.tensor ([1,2,3])                 # from a list\nw = torch.tensor ([1,2,3])                 # from a tuple\nw = torch.tensor (numpy.array ([1,2,3]))   # from a numpy.array\n\n# initialized by size\nw = torch.empty (100, 200)                 # uninitialized, element values are not predictable\nw = torch.zeros (100, 200)                 # all elements initialized with 0.0\nw = torch.ones (100, 200)                  # all elements initialized with 1.0\n\n# initialized by size with random values\nw = torch.rand (100, 200)\nw = torch.randn (100, 200)\nw = torch.randint (5, 10, (100, 200))\n\n# initialized to have the same size, data type and device as another tensor\nx = torch.empty_like (w)\n\n# specify the data type at creation using dtype\nw = torch.tensor ([1,2,3], dtype = torch.float32)\n\n# use the casting method to cast to a new data type\nw.int ()        # w remains a float 32 after the cast\nw = w.int ()    # w changes to an int32 after the cast\n\n# use the to() method to cast to a new type\nw = w.to (torch.float64)\nw = w.to (dtype = torch.float64)\n\n# Python automatucally converts data types during operations\nx = torch.tensor ([1,2,3], dtype = torch.int32)\ny = torch.tensor ([1,2,3], dtype = torch.float32)\nz = x + y\nprint (z.dtype)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:18.442441Z","iopub.execute_input":"2023-12-15T18:27:18.442958Z","iopub.status.idle":"2023-12-15T18:27:18.475479Z","shell.execute_reply.started":"2023-12-15T18:27:18.442922Z","shell.execute_reply":"2023-12-15T18:27:18.474602Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"torch.float32\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Indexing, sdlicing, combining and splitting tensors**","metadata":{}},{"cell_type":"code","source":"x = torch.tensor ([[1, 2], [3, 4], [5, 6], [7, 8]])\nprint (x)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:18.478102Z","iopub.execute_input":"2023-12-15T18:27:18.4789Z","iopub.status.idle":"2023-12-15T18:27:18.485274Z","shell.execute_reply.started":"2023-12-15T18:27:18.478866Z","shell.execute_reply":"2023-12-15T18:27:18.48423Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"tensor([[1, 2],\n        [3, 4],\n        [5, 6],\n        [7, 8]])\n","output_type":"stream"}]},{"cell_type":"code","source":"# indexing, returns a tensor\nprint (x[1, 1])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:18.486446Z","iopub.execute_input":"2023-12-15T18:27:18.487082Z","iopub.status.idle":"2023-12-15T18:27:18.495096Z","shell.execute_reply.started":"2023-12-15T18:27:18.487048Z","shell.execute_reply":"2023-12-15T18:27:18.494185Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"tensor(4)\n","output_type":"stream"}]},{"cell_type":"code","source":"# indexing, returns a value as a Python number\nprint (x[1,1].item ())","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:18.496789Z","iopub.execute_input":"2023-12-15T18:27:18.497149Z","iopub.status.idle":"2023-12-15T18:27:18.505912Z","shell.execute_reply.started":"2023-12-15T18:27:18.497118Z","shell.execute_reply":"2023-12-15T18:27:18.504864Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"4\n","output_type":"stream"}]},{"cell_type":"code","source":"# slicing\nprint (x[:2, 1])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:18.507247Z","iopub.execute_input":"2023-12-15T18:27:18.507576Z","iopub.status.idle":"2023-12-15T18:27:18.524085Z","shell.execute_reply.started":"2023-12-15T18:27:18.507545Z","shell.execute_reply":"2023-12-15T18:27:18.52291Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"tensor([2, 4])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Boolean indexing\n# only keeps elements less than 4\nprint (x [x < 4])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:18.525549Z","iopub.execute_input":"2023-12-15T18:27:18.525874Z","iopub.status.idle":"2023-12-15T18:27:18.545165Z","shell.execute_reply.started":"2023-12-15T18:27:18.525843Z","shell.execute_reply":"2023-12-15T18:27:18.544149Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"tensor([1, 2, 3])\n","output_type":"stream"}]},{"cell_type":"code","source":"# transpose array\nprint (x.t())","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:18.546233Z","iopub.execute_input":"2023-12-15T18:27:18.546857Z","iopub.status.idle":"2023-12-15T18:27:18.553264Z","shell.execute_reply.started":"2023-12-15T18:27:18.546822Z","shell.execute_reply":"2023-12-15T18:27:18.552208Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"tensor([[1, 3, 5, 7],\n        [2, 4, 6, 8]])\n","output_type":"stream"}]},{"cell_type":"code","source":"# change shape\nprint (x.view ((2,4)))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:18.557943Z","iopub.execute_input":"2023-12-15T18:27:18.558228Z","iopub.status.idle":"2023-12-15T18:27:18.563618Z","shell.execute_reply.started":"2023-12-15T18:27:18.558205Z","shell.execute_reply":"2023-12-15T18:27:18.562599Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"tensor([[1, 2, 3, 4],\n        [5, 6, 7, 8]])\n","output_type":"stream"}]},{"cell_type":"code","source":"# combining tensors \ny = torch.stack ((x, x))\nprint (y)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:18.565296Z","iopub.execute_input":"2023-12-15T18:27:18.565605Z","iopub.status.idle":"2023-12-15T18:27:18.578571Z","shell.execute_reply.started":"2023-12-15T18:27:18.565576Z","shell.execute_reply":"2023-12-15T18:27:18.577689Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"tensor([[[1, 2],\n         [3, 4],\n         [5, 6],\n         [7, 8]],\n\n        [[1, 2],\n         [3, 4],\n         [5, 6],\n         [7, 8]]])\n","output_type":"stream"}]},{"cell_type":"code","source":"# splitting tensors \na, b = x.unbind (dim = 1)\nprint (a, b)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:18.579749Z","iopub.execute_input":"2023-12-15T18:27:18.580076Z","iopub.status.idle":"2023-12-15T18:27:18.585611Z","shell.execute_reply.started":"2023-12-15T18:27:18.580053Z","shell.execute_reply":"2023-12-15T18:27:18.584764Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"tensor([1, 3, 5, 7]) tensor([2, 4, 6, 8])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Automatic differentiation**","metadata":{}},{"cell_type":"code","source":"x = torch.tensor ([[1,2,3], [4,5,6]], \n                 dtype = torch.float, requires_grad = True)\nprint (x)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:18.58689Z","iopub.execute_input":"2023-12-15T18:27:18.587136Z","iopub.status.idle":"2023-12-15T18:27:18.609586Z","shell.execute_reply.started":"2023-12-15T18:27:18.587115Z","shell.execute_reply":"2023-12-15T18:27:18.608718Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"tensor([[1., 2., 3.],\n        [4., 5., 6.]], requires_grad=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"f = x.pow(2).sum()\nprint (f)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:18.610681Z","iopub.execute_input":"2023-12-15T18:27:18.610994Z","iopub.status.idle":"2023-12-15T18:27:18.619134Z","shell.execute_reply.started":"2023-12-15T18:27:18.610963Z","shell.execute_reply":"2023-12-15T18:27:18.618218Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"tensor(91., grad_fn=<SumBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"f.backward ()\nprint (x.grad)  # df/dx = 2x","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:18.620119Z","iopub.execute_input":"2023-12-15T18:27:18.620431Z","iopub.status.idle":"2023-12-15T18:27:18.653444Z","shell.execute_reply.started":"2023-12-15T18:27:18.620409Z","shell.execute_reply":"2023-12-15T18:27:18.652594Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"tensor([[ 2.,  4.,  6.],\n        [ 8., 10., 12.]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Deep learning with PyTorch**","metadata":{}},{"cell_type":"code","source":"# import dataset CIFAR10\nfrom torchvision.datasets import CIFAR10\n\n# load train data\ntrain_data = CIFAR10 (root = \"./train/\", train = True, download = True)\nprint (train_data)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:18.654571Z","iopub.execute_input":"2023-12-15T18:27:18.654907Z","iopub.status.idle":"2023-12-15T18:27:26.576486Z","shell.execute_reply.started":"2023-12-15T18:27:18.654874Z","shell.execute_reply":"2023-12-15T18:27:26.575554Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./train/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:03<00:00, 46918065.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./train/cifar-10-python.tar.gz to ./train/\nDataset CIFAR10\n    Number of datapoints: 50000\n    Root location: ./train/\n    Split: Train\n","output_type":"stream"}]},{"cell_type":"code","source":"# mapping numeric labels to class names\nprint (train_data.class_to_idx)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:26.578004Z","iopub.execute_input":"2023-12-15T18:27:26.57837Z","iopub.status.idle":"2023-12-15T18:27:26.58325Z","shell.execute_reply.started":"2023-12-15T18:27:26.578336Z","shell.execute_reply":"2023-12-15T18:27:26.582368Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n","output_type":"stream"}]},{"cell_type":"code","source":"# load text data\ntest_data = CIFAR10 (root = \"./test/\", train = False, download = True)\nprint (test_data)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:26.584298Z","iopub.execute_input":"2023-12-15T18:27:26.584582Z","iopub.status.idle":"2023-12-15T18:27:34.046032Z","shell.execute_reply.started":"2023-12-15T18:27:26.584556Z","shell.execute_reply":"2023-12-15T18:27:34.045093Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./test/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:04<00:00, 35043950.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./test/cifar-10-python.tar.gz to ./test/\nDataset CIFAR10\n    Number of datapoints: 10000\n    Root location: ./test/\n    Split: Test\n","output_type":"stream"}]},{"cell_type":"code","source":"# transorm train data\n# import library\nfrom torchvision import transforms\n\ntrain_transforms = transforms.Compose ([\n    transforms.RandomCrop (32, padding = 4),\n    transforms.RandomHorizontalFlip (),\n    transforms.ToTensor (),\n    # the mean and standard deviation values here were predetermined\n    transforms.Normalize (\n    mean = (0.4914, 0.4822, 0.4465),\n    std = (0.2023, 0.1994, 0.2010))])\n\ntrain_data = CIFAR10 (root = \"./train/\", train = True,\n                   download = True, transform = train_transforms)\nprint (train_data.transforms)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:34.047262Z","iopub.execute_input":"2023-12-15T18:27:34.047544Z","iopub.status.idle":"2023-12-15T18:27:34.883834Z","shell.execute_reply.started":"2023-12-15T18:27:34.047513Z","shell.execute_reply":"2023-12-15T18:27:34.882974Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nStandardTransform\nTransform: Compose(\n               RandomCrop(size=(32, 32), padding=4)\n               RandomHorizontalFlip(p=0.5)\n               ToTensor()\n               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n           )\n","output_type":"stream"}]},{"cell_type":"code","source":"# transform test data\ntest_transforms = transforms.Compose ([\n    transforms.ToTensor (),\n    transforms.Normalize (\n    (0.4914, 0.4822, 0.4465),\n    (0.2023, 0.1994, 0.2010))])\n\ntest_data = CIFAR10 (root = \"./test/\", train = False,\n                                         transform = test_transforms)\n\nprint (test_data)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:34.885049Z","iopub.execute_input":"2023-12-15T18:27:34.885343Z","iopub.status.idle":"2023-12-15T18:27:35.248438Z","shell.execute_reply.started":"2023-12-15T18:27:34.885317Z","shell.execute_reply":"2023-12-15T18:27:35.247558Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Dataset CIFAR10\n    Number of datapoints: 10000\n    Root location: ./test/\n    Split: Test\n    StandardTransform\nTransform: Compose(\n               ToTensor()\n               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n           )\n","output_type":"stream"}]},{"cell_type":"code","source":"# data batching\ntrainloader = torch.utils.data.DataLoader (train_data,\n                                          batch_size = 16, shuffle = True)\ndata_batch, labels_batch = next (iter (trainloader))\nprint (data_batch.size ())","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:35.249773Z","iopub.execute_input":"2023-12-15T18:27:35.25054Z","iopub.status.idle":"2023-12-15T18:27:35.276837Z","shell.execute_reply.started":"2023-12-15T18:27:35.250504Z","shell.execute_reply":"2023-12-15T18:27:35.276052Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"torch.Size([16, 3, 32, 32])\n","output_type":"stream"}]},{"cell_type":"code","source":"# create a dataloader for test data\ntestloader = torch.utils.data.DataLoader (test_data,\n                                         batch_size = 16, shuffle = False)\ntorch.utils.data.DataLoader (test_data, batch_size = 1,\n                            shuffle = False, sampler = None,\n                            batch_sampler = None, num_workers = 0,\n                            collate_fn = None, pin_memory = False,\n                            drop_last = False, timeout = 0,\n                            worker_init_fn = None, multiprocessing_context = None,\n                            generator = None)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:35.277725Z","iopub.execute_input":"2023-12-15T18:27:35.277971Z","iopub.status.idle":"2023-12-15T18:27:35.286628Z","shell.execute_reply.started":"2023-12-15T18:27:35.27795Z","shell.execute_reply":"2023-12-15T18:27:35.285799Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<torch.utils.data.dataloader.DataLoader at 0x7ef4b9c528f0>"},"metadata":{}}]},{"cell_type":"code","source":"# create a simple model with torch.nn\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass SimpleNet (nn.Module):\n    \n    def __init__(self):\n        # create layers\n        super (SimpleNet, self).__init__()\n        self.fc1 = nn.Linear (2048, 256)\n        self.fc2 = nn.Linear (256, 64)\n        self.fc3 = nn.Linear(64, 2)\n    \n    def forward (self, x):\n        # define how to model processes data\n        x = x.view (-1, 2048)\n        x = F.relu (self.fc1 (x))\n        x = F.relu (self.fc2 (x))\n        x = F.softmax (self.fc3 (x), dim = 1)\n        return x\n    \n# create the model\nsimplenet = SimpleNet ()\nprint (simplenet)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:35.287747Z","iopub.execute_input":"2023-12-15T18:27:35.288007Z","iopub.status.idle":"2023-12-15T18:27:35.304072Z","shell.execute_reply.started":"2023-12-15T18:27:35.287984Z","shell.execute_reply":"2023-12-15T18:27:35.303326Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"SimpleNet(\n  (fc1): Linear(in_features=2048, out_features=256, bias=True)\n  (fc2): Linear(in_features=256, out_features=64, bias=True)\n  (fc3): Linear(in_features=64, out_features=2, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# forward pass\ninput = torch.rand (2048)\noutput = simplenet (input)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:35.305021Z","iopub.execute_input":"2023-12-15T18:27:35.30531Z","iopub.status.idle":"2023-12-15T18:27:35.352602Z","shell.execute_reply.started":"2023-12-15T18:27:35.305287Z","shell.execute_reply":"2023-12-15T18:27:35.351812Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# create a modernized version of the LeNet5 model\nfrom torch import nn\n\nclass LeNet5 (nn.Module):\n    def __init__(self):\n        super (LeNet5, self).__init__()\n        self.conv1 = nn.Conv2d (3, 6, 5)\n        self.conv2 = nn.Conv2d (6, 16, 5)\n        self.fc1 = nn.Linear (16 * 5 * 5, 120)\n        self.fc2 = nn.Linear (120, 84)\n        self.fc3 = nn.Linear (84, 10)\n        \n    def forward (self, x):\n        x = F.max_pool2d (F.relu (self.conv1 (x)), (2, 2))\n        x = F.max_pool2d (F.relu (self.conv2 (x)), 2)\n        x = x.view (-1, int (x.nelement () / x.shape [0]))\n        x = F.relu (self.fc1 (x))\n        x = F.relu (self.fc2 (x))\n        x = self.fc3 (x)\n        return x\ndevice = (\"cuda\" if torch.cuda.is_available() else 'cpu')\nmodel = LeNet5 ().to (device = device)\n    \n# define the loss function and the optimizer\nfrom torch import optim\n\ncriterion = nn.CrossEntropyLoss ()\noptimizer = optim.SGD (model.parameters (), lr = 0.001, momentum = 0.9)\n\n# create the fundamental training loop\nN_EPOCHS = 10\nfor epoch in range (N_EPOCHS):\n    # outer training loop, loop over 10 epochs\n    epoch_loss = 0.0\n    for inputs, labels in trainloader:\n        inputs = inputs.to(device)\n        labels = labels.to (device)\n        optimizer.zero_grad ()\n        outputs = model (inputs)\n        loss = criterion (outputs, labels)\n        loss.backward ()\n        optimizer.step ()\n        \n        epoch_loss += loss.item()\n    print (\"Epoch: {} Loss: {}\".format (epoch, epoch_loss / len (trainloader)))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:27:35.35389Z","iopub.execute_input":"2023-12-15T18:27:35.354383Z","iopub.status.idle":"2023-12-15T18:31:48.737465Z","shell.execute_reply.started":"2023-12-15T18:27:35.354348Z","shell.execute_reply":"2023-12-15T18:31:48.736533Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch: 0 Loss: 1.9225346839141846\nEpoch: 1 Loss: 1.5957783769226075\nEpoch: 2 Loss: 1.47812850605011\nEpoch: 3 Loss: 1.4003536859130858\nEpoch: 4 Loss: 1.3313431954193116\nEpoch: 5 Loss: 1.2820638471698762\nEpoch: 6 Loss: 1.240735790195465\nEpoch: 7 Loss: 1.205982148628235\nEpoch: 8 Loss: 1.1824983547973633\nEpoch: 9 Loss: 1.1547182168674468\n","output_type":"stream"}]},{"cell_type":"code","source":"# split training dataset into a training dataset and a validation dataset\nfrom torch.utils.data import random_split\ntrain_set, val_set = random_split (train_data, [40000, 10000])\ntrainloader = torch.utils.data.DataLoader (train_set, batch_size = 16,\n                                          shuffle = True)\nvalloader = torch.utils.data.DataLoader (val_set,\n                                        batch_size = 16, shuffle = True)\nprint (len (trainloader))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:31:48.738683Z","iopub.execute_input":"2023-12-15T18:31:48.738978Z","iopub.status.idle":"2023-12-15T18:31:48.74804Z","shell.execute_reply.started":"2023-12-15T18:31:48.738953Z","shell.execute_reply":"2023-12-15T18:31:48.747196Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"2500\n","output_type":"stream"}]},{"cell_type":"code","source":"# define model, loss function and optimizer\nfrom torch import optim\n\nmodel = LeNet5 ().to (device)\ncriterion = nn.CrossEntropyLoss ()\noptimizer = optim.SGD (model.parameters (), lr = 0.001, momentum = 0.9)\n\nN_EPOCHS = 10\nfor epoch in range (N_EPOCHS):\n    \n    # Training \n    train_loss = 0.0\n    model.train ()\n    for inputs, labels in trainloader:\n        inputs = inputs.to (device)\n        labels = labels.to (device)\n        \n        optimizer.zero_grad ()\n        \n        outputs = model (inputs)\n        loss = criterion (outputs, labels)\n        loss.backward ()\n        optimizer.step ()\n        \n        train_loss += loss.item ()\n   \n    # Validation\n    val_loss = 0.0\n    model.eval ()\n    for inputs, labels in valloader:\n        inputs = inputs.to (device)\n        labels = labels.to (device)\n        outputs = model (inputs)\n        loss = criterion (outputs, labels)\n        \n        val_loss += loss.item ()\n    \n    print (\"Epoch: {} Train loss: {} Val Loss: {}\".format (\n    epoch, train_loss / len (trainloader),\n    val_loss / len (valloader)))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:31:48.749209Z","iopub.execute_input":"2023-12-15T18:31:48.749507Z","iopub.status.idle":"2023-12-15T18:35:47.596593Z","shell.execute_reply.started":"2023-12-15T18:31:48.749483Z","shell.execute_reply":"2023-12-15T18:35:47.595693Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch: 0 Train loss: 2.034372169876099 Val Loss: 1.8027442321777343\nEpoch: 1 Train loss: 1.6943701210737228 Val Loss: 1.615640245437622\nEpoch: 2 Train loss: 1.5701430352926253 Val Loss: 1.520080973148346\nEpoch: 3 Train loss: 1.4738453319072724 Val Loss: 1.4430242691040038\nEpoch: 4 Train loss: 1.4043765926837921 Val Loss: 1.3676951006889344\nEpoch: 5 Train loss: 1.349413713479042 Val Loss: 1.33071211643219\nEpoch: 6 Train loss: 1.3071986087560654 Val Loss: 1.303374522781372\nEpoch: 7 Train loss: 1.2610173003196716 Val Loss: 1.272912829208374\nEpoch: 8 Train loss: 1.2320855487585067 Val Loss: 1.2113297019004823\nEpoch: 9 Train loss: 1.2130050191402435 Val Loss: 1.2391934281349182\n","output_type":"stream"}]},{"cell_type":"code","source":"# testing\nnum_correct = 0.0\nfor x_test_batch, y_test_batch in testloader:\n    model.eval()\n    y_test_batch = y_test_batch.to(device)\n    x_test_batch = x_test_batch.to(device)\n    y_pred_batch = model(x_test_batch)\n    _, predicted = torch.max(y_pred_batch, 1)\n    num_correct += (predicted == y_test_batch).float().sum()\n    accuracy = num_correct/(len(testloader) * testloader.batch_size)\n    \nprint(len(testloader), testloader.batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:35:47.602355Z","iopub.execute_input":"2023-12-15T18:35:47.602769Z","iopub.status.idle":"2023-12-15T18:35:50.339693Z","shell.execute_reply.started":"2023-12-15T18:35:47.602741Z","shell.execute_reply":"2023-12-15T18:35:50.338774Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"625 16\n","output_type":"stream"}]},{"cell_type":"code","source":"# save the model\ntorch.save(model.state_dict(), \"./lenet5_model.pt\")\nmodel = LeNet5().to(device)\nmodel.load_state_dict(torch.load(\"./lenet5_model.pt\"))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:35:50.340737Z","iopub.execute_input":"2023-12-15T18:35:50.341009Z","iopub.status.idle":"2023-12-15T18:35:50.356983Z","shell.execute_reply.started":"2023-12-15T18:35:50.340985Z","shell.execute_reply":"2023-12-15T18:35:50.356136Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nvgg16 = torch.hub.load('pytorch/vision','vgg16', pretrained=True)\ndependencies = ['torch']\nfrom torchvision.models.vgg import vgg16\ndependencies = ['torch']\nfrom torchvision.models.vgg import vgg16 as _vgg16\n# vgg16 is the name of the entrypoint\ndef vgg16(weights=False, **kwargs):\n    \"\"\" # This docstring shows up in hub.help(): VGG16 model\n    pretrained (bool): kwargs,\n    load pretrained weights into the model\n    \"\"\"\n    # Call the model; load pretrained weights\n    model = _vgg16(weights=weights, **kwargs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:35:50.358132Z","iopub.execute_input":"2023-12-15T18:35:50.358485Z","iopub.status.idle":"2023-12-15T18:35:56.130754Z","shell.execute_reply.started":"2023-12-15T18:35:50.358452Z","shell.execute_reply":"2023-12-15T18:35:56.12974Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/pytorch/vision/zipball/main\" to /root/.cache/torch/hub/main.zip\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:01<00:00, 321MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"from torchvision import datasets, models\nfrom torchvision import transforms\nfrom io import BytesIO\nfrom urllib.request import urlopen\nfrom zipfile import ZipFile\nzipurl = 'https://pytorch.tips/bee-zip'\nwith urlopen(zipurl) as zipresp:\n    with ZipFile(BytesIO(zipresp.read())) as zfile:\n        zfile.extractall('./data')\n    \ntrain_transforms = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),transforms.Normalize([0.485, 0.456,0.406],\n                                               [0.229, 0.224, 0.225])])\nval_transforms = transforms.Compose([\n    transforms.Resize(256),transforms.CenterCrop(224),\n    transforms.ToTensor(),transforms.Normalize(\n        [0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n\ntrain_dataset = datasets.ImageFolder(root='data/hymenoptera_data/train',\n                                     transform=train_transforms)\nval_dataset = datasets.ImageFolder(root='data/hymenoptera_data/val',\n                                   transform=val_transforms)\n\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset,batch_size=4,\n    shuffle=True,num_workers=4)\nval_loader = torch.utils.data.DataLoader(\n    val_dataset,batch_size=4,\n    shuffle=True,num_workers=4)\n\nmodel = models.resnet18(pretrained=True)\nprint(model.fc)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:35:56.13197Z","iopub.execute_input":"2023-12-15T18:35:56.132295Z","iopub.status.idle":"2023-12-15T18:35:57.855098Z","shell.execute_reply.started":"2023-12-15T18:35:56.13227Z","shell.execute_reply":"2023-12-15T18:35:57.854205Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 180MB/s]","output_type":"stream"},{"name":"stdout","text":"Linear(in_features=512, out_features=1000, bias=True)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# training and validation\nfrom torch.optim.lr_scheduler import StepLR\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(),\n                      lr=0.001,momentum=0.9)\nexp_lr_scheduler = StepLR(optimizer,step_size=7,\n                          gamma=0.1)\n\nnum_epochs=25\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    running_corrects = 0\n    \n    for inputs, labels in train_loader:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        _, preds = torch.max(outputs,1)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()/inputs.size(0)\n        running_corrects += \\\n        torch.sum(preds == labels.data)/inputs.size(0)\n        exp_lr_scheduler.step()\n        train_epoch_loss = running_loss / len(train_loader)\n        train_epoch_acc = running_corrects / len(train_loader)\n        model.eval()\n        running_loss = 0.1\n        running_corrects = 0\n        \n        for inputs, labels in val_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs,1)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item()/inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data) \\\n        /inputs.size(0)\n            epoch_loss = running_loss / len(val_loader)\n            epoch_acc = \\\n            running_corrects.double() / len(val_loader)\n            print(\"Train: Loss: {:.4f} Acc: {:.4f}\" \" Val: Loss: {:.4f}\"\n              \" Acc: {:.4f}\".format(train_epoch_loss,\n                                    train_epoch_acc,\n                                    epoch_loss,\n                                    epoch_acc))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:44:44.969526Z","iopub.execute_input":"2023-12-15T18:44:44.970178Z","iopub.status.idle":"2023-12-15T18:45:14.784221Z","shell.execute_reply.started":"2023-12-15T18:44:44.970127Z","shell.execute_reply":"2023-12-15T18:45:14.783046Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Train: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.0351 Acc: 0.0256\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.0511 Acc: 0.0449\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.0664 Acc: 0.0577\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.0968 Acc: 0.0641\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.1151 Acc: 0.0769\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.1514 Acc: 0.0769\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.1730 Acc: 0.0897\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.1977 Acc: 0.1026\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.2167 Acc: 0.1154\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.2428 Acc: 0.1218\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.2603 Acc: 0.1346\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.2924 Acc: 0.1346\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.3132 Acc: 0.1538\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.3367 Acc: 0.1667\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.3558 Acc: 0.1795\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.3735 Acc: 0.1923\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.3977 Acc: 0.2051\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.4107 Acc: 0.2308\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.4292 Acc: 0.2436\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.4546 Acc: 0.2500\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.4794 Acc: 0.2564\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.4971 Acc: 0.2628\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.5227 Acc: 0.2756\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.5444 Acc: 0.2821\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.5650 Acc: 0.2949\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.5830 Acc: 0.3077\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.6131 Acc: 0.3141\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.6303 Acc: 0.3333\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.6427 Acc: 0.3526\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.6595 Acc: 0.3654\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.6758 Acc: 0.3782\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.6968 Acc: 0.3910\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.7159 Acc: 0.4038\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.7296 Acc: 0.4167\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.7523 Acc: 0.4295\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.7721 Acc: 0.4359\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.8001 Acc: 0.4423\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.8316 Acc: 0.4423\nTrain: Loss: 0.0114 Acc: 0.0082 Val: Loss: 0.9303 Acc: 0.4423\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 0.9616 Acc: 0.4744\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 0.9888 Acc: 0.4808\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.0158 Acc: 0.4936\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.0325 Acc: 0.5064\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.0437 Acc: 0.5256\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.0565 Acc: 0.5449\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.0734 Acc: 0.5513\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.0916 Acc: 0.5641\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.1016 Acc: 0.5833\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.1343 Acc: 0.5897\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.1526 Acc: 0.6026\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.1765 Acc: 0.6154\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.1892 Acc: 0.6346\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.2122 Acc: 0.6410\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.2338 Acc: 0.6538\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.2595 Acc: 0.6603\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.2828 Acc: 0.6731\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.2998 Acc: 0.6859\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.3167 Acc: 0.6987\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.3435 Acc: 0.7051\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.3571 Acc: 0.7179\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.3784 Acc: 0.7308\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.4032 Acc: 0.7372\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.4160 Acc: 0.7564\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.4343 Acc: 0.7692\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.4627 Acc: 0.7756\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.4822 Acc: 0.7949\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.5057 Acc: 0.8077\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.5250 Acc: 0.8205\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.5486 Acc: 0.8269\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.5745 Acc: 0.8397\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.5962 Acc: 0.8462\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.6196 Acc: 0.8526\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.6393 Acc: 0.8590\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.6499 Acc: 0.8782\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.6626 Acc: 0.8974\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.6787 Acc: 0.9167\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.6951 Acc: 0.9295\nTrain: Loss: 0.6040 Acc: 0.2951 Val: Loss: 1.7901 Acc: 0.9295\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 1.8228 Acc: 0.9615\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 1.8506 Acc: 0.9744\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 1.8592 Acc: 1.0000\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 1.8763 Acc: 1.0064\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 1.9003 Acc: 1.0192\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 1.9284 Acc: 1.0256\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 1.9508 Acc: 1.0385\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 1.9662 Acc: 1.0513\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 1.9968 Acc: 1.0513\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.0075 Acc: 1.0641\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.0186 Acc: 1.0897\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.0413 Acc: 1.1026\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.0538 Acc: 1.1218\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.0684 Acc: 1.1410\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.0868 Acc: 1.1474\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.1098 Acc: 1.1538\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.1324 Acc: 1.1603\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.1487 Acc: 1.1731\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.1576 Acc: 1.1987\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.1849 Acc: 1.2051\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.1951 Acc: 1.2244\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.2165 Acc: 1.2372\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.2318 Acc: 1.2564\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.2465 Acc: 1.2692\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.2631 Acc: 1.2821\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.2764 Acc: 1.2949\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.2938 Acc: 1.3077\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.3093 Acc: 1.3269\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.3184 Acc: 1.3462\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.3297 Acc: 1.3654\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.3543 Acc: 1.3718\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.3751 Acc: 1.3846\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.3882 Acc: 1.3974\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.4124 Acc: 1.4038\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.4313 Acc: 1.4167\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.4464 Acc: 1.4295\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.4558 Acc: 1.4487\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.4814 Acc: 1.4551\nTrain: Loss: 1.1529 Acc: 0.6066 Val: Loss: 2.4958 Acc: 1.4808\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.5342 Acc: 1.5064\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.5512 Acc: 1.5192\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.5828 Acc: 1.5192\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.6011 Acc: 1.5256\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.6245 Acc: 1.5385\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.6490 Acc: 1.5449\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.6700 Acc: 1.5577\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.6830 Acc: 1.5769\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.7008 Acc: 1.5897\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.7125 Acc: 1.6090\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.7238 Acc: 1.6282\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.7473 Acc: 1.6346\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.7558 Acc: 1.6538\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.7647 Acc: 1.6731\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.7820 Acc: 1.6795\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.7970 Acc: 1.6923\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.8171 Acc: 1.7051\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.8289 Acc: 1.7244\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.8388 Acc: 1.7436\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.8638 Acc: 1.7564\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.8753 Acc: 1.7692\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.8916 Acc: 1.7756\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.9234 Acc: 1.7756\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.9388 Acc: 1.7949\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.9611 Acc: 1.8013\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.9699 Acc: 1.8205\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.9805 Acc: 1.8397\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.9906 Acc: 1.8590\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 2.9990 Acc: 1.8846\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 3.0115 Acc: 1.9038\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 3.0236 Acc: 1.9167\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 3.0381 Acc: 1.9295\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 3.0545 Acc: 1.9359\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 3.0627 Acc: 1.9551\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 3.0830 Acc: 1.9679\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 3.1141 Acc: 1.9744\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 3.1335 Acc: 1.9872\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 3.1613 Acc: 2.0000\nTrain: Loss: 1.6078 Acc: 0.9549 Val: Loss: 3.1722 Acc: 2.0256\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.2003 Acc: 2.0641\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.2219 Acc: 2.0769\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.2354 Acc: 2.0962\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.2425 Acc: 2.1154\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.2533 Acc: 2.1346\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.2720 Acc: 2.1538\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.2934 Acc: 2.1667\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.3061 Acc: 2.1795\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.3147 Acc: 2.1987\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.3249 Acc: 2.2179\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.3378 Acc: 2.2308\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.3498 Acc: 2.2500\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.3584 Acc: 2.2692\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.3680 Acc: 2.2885\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.3830 Acc: 2.3077\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.4004 Acc: 2.3269\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.4177 Acc: 2.3397\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.4257 Acc: 2.3526\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.4338 Acc: 2.3718\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.4484 Acc: 2.3846\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.4794 Acc: 2.3910\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.4888 Acc: 2.4103\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.5059 Acc: 2.4231\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.5178 Acc: 2.4423\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.5289 Acc: 2.4551\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.5414 Acc: 2.4679\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.5509 Acc: 2.4872\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.5651 Acc: 2.5064\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.5752 Acc: 2.5256\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.6006 Acc: 2.5321\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.6185 Acc: 2.5449\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.6443 Acc: 2.5577\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.6591 Acc: 2.5641\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.6725 Acc: 2.5833\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.6883 Acc: 2.5962\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.7135 Acc: 2.5962\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.7333 Acc: 2.6026\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.7429 Acc: 2.6218\nTrain: Loss: 2.0352 Acc: 1.3074 Val: Loss: 3.8240 Acc: 2.6218\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 3.8415 Acc: 2.6603\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 3.8497 Acc: 2.6795\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 3.8641 Acc: 2.6923\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 3.8768 Acc: 2.7051\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 3.8883 Acc: 2.7179\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 3.8944 Acc: 2.7372\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 3.9020 Acc: 2.7564\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 3.9199 Acc: 2.7692\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 3.9323 Acc: 2.7821\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 3.9507 Acc: 2.7885\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 3.9606 Acc: 2.8013\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 3.9668 Acc: 2.8269\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 3.9768 Acc: 2.8397\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 3.9943 Acc: 2.8526\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.0063 Acc: 2.8654\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.0136 Acc: 2.8846\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.0257 Acc: 2.9038\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.0291 Acc: 2.9295\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.0374 Acc: 2.9487\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.0426 Acc: 2.9679\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.0593 Acc: 2.9808\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.0827 Acc: 2.9872\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.1117 Acc: 2.9872\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.1411 Acc: 2.9936\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.1503 Acc: 3.0128\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.1605 Acc: 3.0321\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.1742 Acc: 3.0449\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.2005 Acc: 3.0577\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.2064 Acc: 3.0769\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.2209 Acc: 3.0833\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.2397 Acc: 3.0897\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.2505 Acc: 3.1090\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.2758 Acc: 3.1218\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.2921 Acc: 3.1282\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.3007 Acc: 3.1474\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.3162 Acc: 3.1603\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.3357 Acc: 3.1667\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.3517 Acc: 3.1859\nTrain: Loss: 2.4527 Acc: 1.6885 Val: Loss: 4.4217 Acc: 3.1859\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.4590 Acc: 3.1923\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.4702 Acc: 3.2051\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.4918 Acc: 3.2179\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.5066 Acc: 3.2244\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.5218 Acc: 3.2372\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.5409 Acc: 3.2500\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.5458 Acc: 3.2756\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.5594 Acc: 3.2885\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.5693 Acc: 3.3077\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.5767 Acc: 3.3269\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.5969 Acc: 3.3397\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.6022 Acc: 3.3590\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.6086 Acc: 3.3846\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.6237 Acc: 3.3910\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.6299 Acc: 3.4103\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.6409 Acc: 3.4231\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.6472 Acc: 3.4423\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.6589 Acc: 3.4551\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.6644 Acc: 3.4808\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.6676 Acc: 3.5064\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.6867 Acc: 3.5064\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.7059 Acc: 3.5064\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.7113 Acc: 3.5256\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.7214 Acc: 3.5385\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.7296 Acc: 3.5513\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.7332 Acc: 3.5769\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.7400 Acc: 3.5897\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.7523 Acc: 3.5897\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.7603 Acc: 3.6090\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.7643 Acc: 3.6282\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.7768 Acc: 3.6346\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.7896 Acc: 3.6474\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.7916 Acc: 3.6731\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.7965 Acc: 3.6987\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.8050 Acc: 3.7179\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.8161 Acc: 3.7308\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.8243 Acc: 3.7500\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.8348 Acc: 3.7628\nTrain: Loss: 2.8411 Acc: 2.0369 Val: Loss: 4.8422 Acc: 3.7885\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 4.8647 Acc: 3.8141\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 4.8705 Acc: 3.8397\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 4.8802 Acc: 3.8590\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 4.8905 Acc: 3.8782\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 4.9043 Acc: 3.8910\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 4.9135 Acc: 3.9038\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 4.9303 Acc: 3.9167\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 4.9383 Acc: 3.9295\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 4.9521 Acc: 3.9423\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 4.9577 Acc: 3.9679\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 4.9668 Acc: 3.9872\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 4.9733 Acc: 4.0064\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 4.9988 Acc: 4.0128\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.0076 Acc: 4.0256\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.0145 Acc: 4.0513\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.0265 Acc: 4.0641\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.0384 Acc: 4.0833\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.0516 Acc: 4.1026\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.0698 Acc: 4.1154\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.0761 Acc: 4.1346\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.0965 Acc: 4.1410\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.1008 Acc: 4.1667\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.1123 Acc: 4.1859\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.1181 Acc: 4.2051\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.1327 Acc: 4.2115\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.1376 Acc: 4.2308\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.1478 Acc: 4.2372\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.1524 Acc: 4.2564\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.1630 Acc: 4.2756\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.1730 Acc: 4.2885\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.1750 Acc: 4.3141\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.1786 Acc: 4.3397\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.1932 Acc: 4.3526\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.2023 Acc: 4.3654\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.2062 Acc: 4.3910\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.2159 Acc: 4.4038\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.2335 Acc: 4.4103\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.2397 Acc: 4.4359\nTrain: Loss: 3.0982 Acc: 2.4344 Val: Loss: 5.2478 Acc: 4.4615\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.2624 Acc: 4.4936\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.2640 Acc: 4.5192\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.2716 Acc: 4.5256\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.2856 Acc: 4.5321\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.2928 Acc: 4.5513\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.3015 Acc: 4.5705\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.3139 Acc: 4.5833\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.3324 Acc: 4.5833\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.3371 Acc: 4.6026\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.3391 Acc: 4.6282\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.3517 Acc: 4.6474\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.3618 Acc: 4.6603\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.3687 Acc: 4.6859\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.3772 Acc: 4.7051\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.3823 Acc: 4.7244\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.3873 Acc: 4.7500\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.3920 Acc: 4.7756\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.4022 Acc: 4.7949\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.4059 Acc: 4.8205\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.4143 Acc: 4.8397\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.4242 Acc: 4.8526\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.4402 Acc: 4.8590\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.4417 Acc: 4.8846\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.4514 Acc: 4.8974\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.4592 Acc: 4.9231\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.4650 Acc: 4.9423\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.4770 Acc: 4.9615\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.4962 Acc: 4.9679\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.5077 Acc: 4.9808\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.5120 Acc: 5.0064\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.5234 Acc: 5.0256\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.5267 Acc: 5.0513\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.5367 Acc: 5.0641\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.5419 Acc: 5.0833\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.5574 Acc: 5.0962\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.5697 Acc: 5.1154\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.5741 Acc: 5.1410\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.5866 Acc: 5.1538\nTrain: Loss: 3.3586 Acc: 2.8648 Val: Loss: 5.5947 Acc: 5.1795\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.6048 Acc: 5.2244\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.6158 Acc: 5.2436\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.6227 Acc: 5.2628\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.6300 Acc: 5.2821\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.6382 Acc: 5.3013\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.6428 Acc: 5.3205\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.6560 Acc: 5.3397\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.6651 Acc: 5.3590\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.6716 Acc: 5.3782\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.6779 Acc: 5.3974\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.6869 Acc: 5.4103\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.6959 Acc: 5.4231\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.7141 Acc: 5.4295\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.7227 Acc: 5.4487\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.7322 Acc: 5.4679\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.7340 Acc: 5.4936\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.7470 Acc: 5.5064\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.7559 Acc: 5.5192\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.7598 Acc: 5.5449\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.7668 Acc: 5.5641\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.7753 Acc: 5.5833\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.7843 Acc: 5.6026\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.7969 Acc: 5.6154\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.8043 Acc: 5.6346\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.8109 Acc: 5.6538\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.8212 Acc: 5.6667\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.8355 Acc: 5.6795\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.8565 Acc: 5.6859\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.8713 Acc: 5.6923\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.8736 Acc: 5.7179\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.8900 Acc: 5.7244\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.8978 Acc: 5.7436\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.9011 Acc: 5.7692\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.9025 Acc: 5.7949\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.9128 Acc: 5.8077\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.9310 Acc: 5.8205\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.9392 Acc: 5.8397\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.9410 Acc: 5.8654\nTrain: Loss: 3.5799 Acc: 3.3279 Val: Loss: 5.9497 Acc: 5.8910\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 5.9760 Acc: 5.9103\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 5.9789 Acc: 5.9359\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 5.9957 Acc: 5.9423\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.0163 Acc: 5.9551\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.0229 Acc: 5.9679\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.0337 Acc: 5.9808\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.0394 Acc: 6.0000\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.0471 Acc: 6.0192\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.0575 Acc: 6.0385\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.0664 Acc: 6.0513\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.0748 Acc: 6.0705\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.0778 Acc: 6.0962\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.0848 Acc: 6.1154\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.0932 Acc: 6.1346\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.1043 Acc: 6.1474\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.1232 Acc: 6.1474\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.1392 Acc: 6.1538\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.1508 Acc: 6.1731\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.1573 Acc: 6.1923\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.1615 Acc: 6.2179\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.1759 Acc: 6.2308\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.1802 Acc: 6.2500\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.1866 Acc: 6.2692\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.1952 Acc: 6.2885\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.2154 Acc: 6.2949\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.2204 Acc: 6.3141\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.2332 Acc: 6.3333\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.2405 Acc: 6.3526\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.2464 Acc: 6.3718\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.2534 Acc: 6.3846\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.2668 Acc: 6.4038\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.2762 Acc: 6.4231\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.2798 Acc: 6.4487\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.2948 Acc: 6.4551\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.2956 Acc: 6.4808\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.2990 Acc: 6.5064\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.3118 Acc: 6.5192\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.3229 Acc: 6.5321\nTrain: Loss: 3.8131 Acc: 3.7746 Val: Loss: 6.3679 Acc: 6.5321\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.3797 Acc: 6.5769\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.3969 Acc: 6.5833\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.4046 Acc: 6.6026\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.4186 Acc: 6.6090\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.4243 Acc: 6.6282\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.4272 Acc: 6.6538\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.4348 Acc: 6.6731\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.4462 Acc: 6.6859\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.4567 Acc: 6.6987\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.4643 Acc: 6.7179\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.4815 Acc: 6.7308\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.4880 Acc: 6.7500\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.4921 Acc: 6.7756\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.5036 Acc: 6.7885\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.5170 Acc: 6.7949\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.5219 Acc: 6.8077\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.5340 Acc: 6.8205\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.5477 Acc: 6.8269\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.5526 Acc: 6.8526\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.5631 Acc: 6.8590\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.5717 Acc: 6.8782\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.5775 Acc: 6.9038\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.5890 Acc: 6.9167\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.5919 Acc: 6.9423\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.5958 Acc: 6.9679\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.6056 Acc: 6.9744\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.6139 Acc: 6.9936\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.6208 Acc: 7.0128\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.6349 Acc: 7.0192\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.6431 Acc: 7.0449\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.6549 Acc: 7.0577\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.6723 Acc: 7.0705\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.6860 Acc: 7.0897\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.6972 Acc: 7.1026\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.7055 Acc: 7.1282\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.7082 Acc: 7.1538\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.7188 Acc: 7.1731\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.7310 Acc: 7.1923\nTrain: Loss: 4.0751 Acc: 4.1926 Val: Loss: 6.7748 Acc: 7.1923\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.7930 Acc: 7.2372\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.8072 Acc: 7.2500\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.8188 Acc: 7.2628\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.8359 Acc: 7.2756\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.8478 Acc: 7.2885\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.8577 Acc: 7.3077\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.8659 Acc: 7.3205\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.8924 Acc: 7.3205\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.8999 Acc: 7.3397\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.9115 Acc: 7.3526\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.9227 Acc: 7.3718\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.9243 Acc: 7.3974\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.9321 Acc: 7.4103\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.9415 Acc: 7.4231\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.9546 Acc: 7.4359\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.9614 Acc: 7.4551\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.9860 Acc: 7.4615\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.9885 Acc: 7.4872\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 6.9971 Acc: 7.5064\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.0023 Acc: 7.5321\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.0122 Acc: 7.5513\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.0229 Acc: 7.5705\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.0344 Acc: 7.5833\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.0381 Acc: 7.6090\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.0390 Acc: 7.6346\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.0489 Acc: 7.6538\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.0640 Acc: 7.6603\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.0746 Acc: 7.6731\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.0839 Acc: 7.6987\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.0935 Acc: 7.7179\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.1027 Acc: 7.7308\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.1108 Acc: 7.7436\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.1151 Acc: 7.7628\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.1193 Acc: 7.7821\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.1240 Acc: 7.8013\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.1332 Acc: 7.8205\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.1442 Acc: 7.8333\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.1508 Acc: 7.8590\nTrain: Loss: 4.3422 Acc: 4.6107 Val: Loss: 7.1929 Acc: 7.8590\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.2214 Acc: 7.8782\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.2318 Acc: 7.8910\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.2435 Acc: 7.9103\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.2469 Acc: 7.9359\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.2506 Acc: 7.9551\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.2556 Acc: 7.9744\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.2591 Acc: 7.9936\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.2667 Acc: 8.0128\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.2690 Acc: 8.0385\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.2773 Acc: 8.0577\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.2911 Acc: 8.0705\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.3019 Acc: 8.0897\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.3195 Acc: 8.0962\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.3301 Acc: 8.1154\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.3383 Acc: 8.1218\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.3465 Acc: 8.1410\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.3547 Acc: 8.1603\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.3594 Acc: 8.1859\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.3678 Acc: 8.1987\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.3823 Acc: 8.2051\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.3863 Acc: 8.2308\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.3962 Acc: 8.2436\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.4244 Acc: 8.2436\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.4343 Acc: 8.2564\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.4436 Acc: 8.2692\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.4484 Acc: 8.2949\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.4644 Acc: 8.3013\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.4712 Acc: 8.3205\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.4804 Acc: 8.3333\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.4907 Acc: 8.3462\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.5006 Acc: 8.3654\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.5101 Acc: 8.3846\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.5173 Acc: 8.4038\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.5253 Acc: 8.4231\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.5339 Acc: 8.4359\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.5473 Acc: 8.4487\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.5515 Acc: 8.4679\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.5657 Acc: 8.4808\nTrain: Loss: 4.6053 Acc: 5.0328 Val: Loss: 7.5744 Acc: 8.5064\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.5964 Acc: 8.5385\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.6057 Acc: 8.5577\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.6139 Acc: 8.5769\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.6152 Acc: 8.6026\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.6209 Acc: 8.6218\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.6289 Acc: 8.6346\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.6357 Acc: 8.6538\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.6426 Acc: 8.6667\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.6572 Acc: 8.6795\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.6666 Acc: 8.6923\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.6688 Acc: 8.7179\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.6798 Acc: 8.7372\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.6916 Acc: 8.7436\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.7002 Acc: 8.7564\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.7098 Acc: 8.7692\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.7227 Acc: 8.7885\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.7364 Acc: 8.8013\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.7445 Acc: 8.8205\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.7495 Acc: 8.8397\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.7693 Acc: 8.8462\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.7779 Acc: 8.8654\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.7835 Acc: 8.8910\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.7901 Acc: 8.9103\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.8074 Acc: 8.9231\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.8191 Acc: 8.9359\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.8207 Acc: 8.9615\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.8269 Acc: 8.9808\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.8342 Acc: 9.0000\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.8447 Acc: 9.0128\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.8525 Acc: 9.0192\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.8559 Acc: 9.0385\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.8702 Acc: 9.0385\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.8764 Acc: 9.0577\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.8836 Acc: 9.0769\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.9034 Acc: 9.0833\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.9138 Acc: 9.0962\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.9310 Acc: 9.1090\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.9398 Acc: 9.1282\nTrain: Loss: 4.8510 Acc: 5.4467 Val: Loss: 7.9485 Acc: 9.1538\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 7.9610 Acc: 9.1923\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 7.9701 Acc: 9.2115\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 7.9731 Acc: 9.2372\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 7.9804 Acc: 9.2564\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 7.9835 Acc: 9.2821\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 7.9876 Acc: 9.3077\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.0047 Acc: 9.3141\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.0168 Acc: 9.3269\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.0253 Acc: 9.3462\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.0385 Acc: 9.3654\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.0552 Acc: 9.3782\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.0664 Acc: 9.3974\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.0779 Acc: 9.4167\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.0869 Acc: 9.4295\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.0911 Acc: 9.4551\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.0952 Acc: 9.4744\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.0994 Acc: 9.4936\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.1210 Acc: 9.5000\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.1360 Acc: 9.5064\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.1451 Acc: 9.5192\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.1506 Acc: 9.5385\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.1670 Acc: 9.5513\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.1796 Acc: 9.5641\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.1823 Acc: 9.5897\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.1908 Acc: 9.6090\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.1935 Acc: 9.6346\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.2029 Acc: 9.6474\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.2084 Acc: 9.6667\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.2125 Acc: 9.6923\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.2237 Acc: 9.6987\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.2320 Acc: 9.7179\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.2348 Acc: 9.7436\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.2373 Acc: 9.7692\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.2434 Acc: 9.7821\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.2628 Acc: 9.7949\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.2702 Acc: 9.8141\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.2785 Acc: 9.8333\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.2848 Acc: 9.8526\nTrain: Loss: 5.0869 Acc: 5.8648 Val: Loss: 8.2931 Acc: 9.8782\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.3127 Acc: 9.9103\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.3196 Acc: 9.9295\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.3237 Acc: 9.9487\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.3355 Acc: 9.9551\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.3441 Acc: 9.9679\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.3502 Acc: 9.9872\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.3614 Acc: 10.0064\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.3713 Acc: 10.0256\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.3872 Acc: 10.0321\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.3943 Acc: 10.0449\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.3997 Acc: 10.0577\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.4023 Acc: 10.0833\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.4049 Acc: 10.1090\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.4163 Acc: 10.1218\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.4291 Acc: 10.1346\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.4409 Acc: 10.1474\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.4528 Acc: 10.1603\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.4599 Acc: 10.1731\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.4636 Acc: 10.1987\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.4658 Acc: 10.2244\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.4748 Acc: 10.2372\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.4848 Acc: 10.2500\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.5062 Acc: 10.2500\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.5095 Acc: 10.2756\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.5133 Acc: 10.2949\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.5289 Acc: 10.3077\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.5414 Acc: 10.3141\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.5459 Acc: 10.3397\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.5557 Acc: 10.3526\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.5594 Acc: 10.3718\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.5673 Acc: 10.3910\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.5818 Acc: 10.4038\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.5869 Acc: 10.4231\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.6021 Acc: 10.4295\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.6119 Acc: 10.4423\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.6234 Acc: 10.4487\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.6296 Acc: 10.4679\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.6394 Acc: 10.4808\nTrain: Loss: 5.3105 Acc: 6.3238 Val: Loss: 8.6485 Acc: 10.5064\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.6731 Acc: 10.5321\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.6787 Acc: 10.5577\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.6814 Acc: 10.5769\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.6851 Acc: 10.6026\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.6917 Acc: 10.6282\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.6977 Acc: 10.6538\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.7052 Acc: 10.6667\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.7086 Acc: 10.6923\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.7244 Acc: 10.7051\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.7345 Acc: 10.7179\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.7429 Acc: 10.7308\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.7447 Acc: 10.7564\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.7599 Acc: 10.7692\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.7787 Acc: 10.7756\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.7892 Acc: 10.7949\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.7990 Acc: 10.8141\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.8028 Acc: 10.8333\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.8035 Acc: 10.8590\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.8101 Acc: 10.8782\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.8277 Acc: 10.8782\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.8350 Acc: 10.8974\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.8459 Acc: 10.9103\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.8505 Acc: 10.9359\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.8577 Acc: 10.9551\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.8710 Acc: 10.9679\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.8744 Acc: 10.9872\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.8913 Acc: 10.9936\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.9002 Acc: 11.0064\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.9086 Acc: 11.0256\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.9179 Acc: 11.0385\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.9254 Acc: 11.0577\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.9367 Acc: 11.0705\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.9462 Acc: 11.0833\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.9513 Acc: 11.1090\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.9609 Acc: 11.1218\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.9676 Acc: 11.1410\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.9758 Acc: 11.1538\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.9824 Acc: 11.1731\nTrain: Loss: 5.5378 Acc: 6.7254 Val: Loss: 8.9922 Acc: 11.1987\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.0046 Acc: 11.2372\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.0114 Acc: 11.2500\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.0134 Acc: 11.2756\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.0149 Acc: 11.3013\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.0203 Acc: 11.3205\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.0301 Acc: 11.3333\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.0368 Acc: 11.3462\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.0419 Acc: 11.3654\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.0533 Acc: 11.3718\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.0797 Acc: 11.3782\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.0859 Acc: 11.3974\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.0983 Acc: 11.4167\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.1072 Acc: 11.4359\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.1191 Acc: 11.4423\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.1229 Acc: 11.4615\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.1256 Acc: 11.4872\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.1338 Acc: 11.5064\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.1349 Acc: 11.5321\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.1399 Acc: 11.5513\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.1561 Acc: 11.5577\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.1617 Acc: 11.5769\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.1688 Acc: 11.5962\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.1722 Acc: 11.6218\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.1819 Acc: 11.6346\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.1849 Acc: 11.6603\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.2029 Acc: 11.6731\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.2106 Acc: 11.6923\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.2150 Acc: 11.7179\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.2247 Acc: 11.7308\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.2431 Acc: 11.7436\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.2653 Acc: 11.7564\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.2730 Acc: 11.7756\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.2831 Acc: 11.7949\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.2935 Acc: 11.8141\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.2976 Acc: 11.8397\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.3058 Acc: 11.8526\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.3122 Acc: 11.8654\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.3145 Acc: 11.8910\nTrain: Loss: 5.7523 Acc: 7.1762 Val: Loss: 9.3234 Acc: 11.9167\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.3465 Acc: 11.9551\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.3567 Acc: 11.9679\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.3623 Acc: 11.9872\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.3684 Acc: 12.0064\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.3804 Acc: 12.0256\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.3839 Acc: 12.0449\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.3908 Acc: 12.0641\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.4027 Acc: 12.0769\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.4166 Acc: 12.0833\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.4250 Acc: 12.1026\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.4288 Acc: 12.1282\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.4305 Acc: 12.1538\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.4336 Acc: 12.1731\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.4394 Acc: 12.1923\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.4459 Acc: 12.2115\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.4552 Acc: 12.2244\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.4707 Acc: 12.2372\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.4825 Acc: 12.2500\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.4999 Acc: 12.2628\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.5079 Acc: 12.2821\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.5140 Acc: 12.3077\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.5159 Acc: 12.3333\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.5200 Acc: 12.3590\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.5265 Acc: 12.3782\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.5329 Acc: 12.3974\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.5384 Acc: 12.4231\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.5507 Acc: 12.4295\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.5553 Acc: 12.4487\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.5638 Acc: 12.4679\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.5656 Acc: 12.4936\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.5762 Acc: 12.5064\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.5869 Acc: 12.5192\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.5917 Acc: 12.5385\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.6084 Acc: 12.5513\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.6247 Acc: 12.5641\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.6310 Acc: 12.5833\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.6330 Acc: 12.6090\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.6394 Acc: 12.6346\nTrain: Loss: 5.9636 Acc: 7.6352 Val: Loss: 9.6476 Acc: 12.6603\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.6739 Acc: 12.6923\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.6848 Acc: 12.7051\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.6899 Acc: 12.7308\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.7032 Acc: 12.7436\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.7100 Acc: 12.7628\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.7127 Acc: 12.7885\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.7200 Acc: 12.8077\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.7321 Acc: 12.8205\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.7389 Acc: 12.8462\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.7469 Acc: 12.8590\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.7586 Acc: 12.8654\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.7645 Acc: 12.8846\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.7744 Acc: 12.9038\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.7781 Acc: 12.9231\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.7937 Acc: 12.9423\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.7964 Acc: 12.9679\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.8025 Acc: 12.9872\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.8100 Acc: 13.0128\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.8155 Acc: 13.0321\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.8186 Acc: 13.0577\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.8265 Acc: 13.0769\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.8387 Acc: 13.0897\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.8577 Acc: 13.0962\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.8621 Acc: 13.1154\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.8812 Acc: 13.1282\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.8899 Acc: 13.1474\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.9021 Acc: 13.1603\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.9141 Acc: 13.1731\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.9255 Acc: 13.1923\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.9312 Acc: 13.2179\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.9502 Acc: 13.2179\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.9568 Acc: 13.2308\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.9603 Acc: 13.2500\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.9726 Acc: 13.2628\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.9757 Acc: 13.2885\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.9820 Acc: 13.3077\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.9835 Acc: 13.3333\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 9.9869 Acc: 13.3590\nTrain: Loss: 6.1785 Acc: 8.1025 Val: Loss: 10.0272 Acc: 13.3590\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.0578 Acc: 13.3782\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.0629 Acc: 13.3910\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.0681 Acc: 13.4167\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.0781 Acc: 13.4359\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.0884 Acc: 13.4551\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.1046 Acc: 13.4615\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.1107 Acc: 13.4872\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.1191 Acc: 13.5000\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.1381 Acc: 13.5128\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.1420 Acc: 13.5321\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.1508 Acc: 13.5449\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.1629 Acc: 13.5513\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.1681 Acc: 13.5705\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.1806 Acc: 13.5833\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.1981 Acc: 13.5897\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.2142 Acc: 13.5897\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.2202 Acc: 13.6090\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.2241 Acc: 13.6282\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.2293 Acc: 13.6474\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.2379 Acc: 13.6603\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.2480 Acc: 13.6731\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.2577 Acc: 13.6859\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.2617 Acc: 13.7115\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.2664 Acc: 13.7308\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.2755 Acc: 13.7436\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.2825 Acc: 13.7628\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.2848 Acc: 13.7885\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.3016 Acc: 13.8013\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.3040 Acc: 13.8269\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.3113 Acc: 13.8462\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.3172 Acc: 13.8654\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.3212 Acc: 13.8910\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.3264 Acc: 13.9103\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.3332 Acc: 13.9295\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.3375 Acc: 13.9551\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.3459 Acc: 13.9679\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.3514 Acc: 13.9872\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.3563 Acc: 14.0064\nTrain: Loss: 6.4183 Acc: 8.5451 Val: Loss: 10.3651 Acc: 14.0321\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.3834 Acc: 14.0577\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.3981 Acc: 14.0641\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.4015 Acc: 14.0897\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.4079 Acc: 14.1154\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.4167 Acc: 14.1282\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.4275 Acc: 14.1474\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.4282 Acc: 14.1731\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.4310 Acc: 14.1923\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.4498 Acc: 14.2115\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.4598 Acc: 14.2308\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.4689 Acc: 14.2500\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.4806 Acc: 14.2628\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.4907 Acc: 14.2756\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.4972 Acc: 14.2949\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.5078 Acc: 14.3077\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.5118 Acc: 14.3333\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.5204 Acc: 14.3462\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.5281 Acc: 14.3654\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.5324 Acc: 14.3846\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.5371 Acc: 14.4103\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.5437 Acc: 14.4359\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.5478 Acc: 14.4615\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.5548 Acc: 14.4808\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.5674 Acc: 14.4936\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.5759 Acc: 14.5128\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.5819 Acc: 14.5321\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.6013 Acc: 14.5385\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.6049 Acc: 14.5641\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.6204 Acc: 14.5641\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.6237 Acc: 14.5833\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.6274 Acc: 14.6090\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.6454 Acc: 14.6154\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.6495 Acc: 14.6410\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.6614 Acc: 14.6538\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.6688 Acc: 14.6795\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.6847 Acc: 14.6859\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.6900 Acc: 14.7051\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.6940 Acc: 14.7308\nTrain: Loss: 6.6349 Acc: 8.9795 Val: Loss: 10.7340 Acc: 14.7308\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.7586 Acc: 14.7564\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.7655 Acc: 14.7756\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.7688 Acc: 14.8013\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.7795 Acc: 14.8141\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.7946 Acc: 14.8205\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.8057 Acc: 14.8333\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.8089 Acc: 14.8526\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.8220 Acc: 14.8590\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.8285 Acc: 14.8782\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.8397 Acc: 14.8910\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.8550 Acc: 14.8910\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.8642 Acc: 14.9103\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.8729 Acc: 14.9295\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.8811 Acc: 14.9487\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.8918 Acc: 14.9679\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.8957 Acc: 14.9872\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.8979 Acc: 15.0128\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.9061 Acc: 15.0256\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.9083 Acc: 15.0513\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.9131 Acc: 15.0769\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.9237 Acc: 15.0897\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.9259 Acc: 15.1154\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.9309 Acc: 15.1346\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.9389 Acc: 15.1538\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.9598 Acc: 15.1603\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.9721 Acc: 15.1731\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.9860 Acc: 15.1859\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.9867 Acc: 15.2115\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.9953 Acc: 15.2308\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 10.9998 Acc: 15.2500\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 11.0135 Acc: 15.2564\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 11.0285 Acc: 15.2628\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 11.0391 Acc: 15.2756\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 11.0455 Acc: 15.2885\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 11.0559 Acc: 15.3077\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 11.0658 Acc: 15.3269\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 11.0729 Acc: 15.3462\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 11.0788 Acc: 15.3718\nTrain: Loss: 6.8680 Acc: 9.4262 Val: Loss: 11.0873 Acc: 15.3974\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.0947 Acc: 15.4423\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.1050 Acc: 15.4551\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.1227 Acc: 15.4679\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.1311 Acc: 15.4872\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.1381 Acc: 15.5064\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.1488 Acc: 15.5256\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.1551 Acc: 15.5449\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.1616 Acc: 15.5641\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.1670 Acc: 15.5897\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.1725 Acc: 15.6090\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.1780 Acc: 15.6346\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.1801 Acc: 15.6603\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.2003 Acc: 15.6731\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.2082 Acc: 15.6923\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.2133 Acc: 15.7179\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.2222 Acc: 15.7308\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.2355 Acc: 15.7436\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.2463 Acc: 15.7628\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.2587 Acc: 15.7756\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.2674 Acc: 15.7949\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.2757 Acc: 15.8077\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.2879 Acc: 15.8205\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.2936 Acc: 15.8397\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.3049 Acc: 15.8590\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.3137 Acc: 15.8654\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.3196 Acc: 15.8846\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.3213 Acc: 15.9103\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.3391 Acc: 15.9231\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.3502 Acc: 15.9423\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.3575 Acc: 15.9551\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.3595 Acc: 15.9808\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.3833 Acc: 15.9808\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.3964 Acc: 15.9936\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.4035 Acc: 16.0128\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.4156 Acc: 16.0321\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.4183 Acc: 16.0513\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.4295 Acc: 16.0577\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.4370 Acc: 16.0769\nTrain: Loss: 7.0898 Acc: 9.8607 Val: Loss: 11.4770 Acc: 16.0769\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.4927 Acc: 16.1154\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.5010 Acc: 16.1282\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.5059 Acc: 16.1538\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.5163 Acc: 16.1731\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.5313 Acc: 16.1859\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.5343 Acc: 16.2115\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.5489 Acc: 16.2244\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.5691 Acc: 16.2372\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.5732 Acc: 16.2564\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.5772 Acc: 16.2821\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.5830 Acc: 16.3013\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.5848 Acc: 16.3269\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.5951 Acc: 16.3462\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.6005 Acc: 16.3654\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.6071 Acc: 16.3846\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.6143 Acc: 16.3974\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.6250 Acc: 16.4103\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.6427 Acc: 16.4295\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.6461 Acc: 16.4551\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.6617 Acc: 16.4615\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.6727 Acc: 16.4808\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.6914 Acc: 16.4936\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.6972 Acc: 16.5128\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.7086 Acc: 16.5256\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.7170 Acc: 16.5449\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.7240 Acc: 16.5641\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.7379 Acc: 16.5705\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.7417 Acc: 16.5962\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.7459 Acc: 16.6154\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.7535 Acc: 16.6346\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.7672 Acc: 16.6474\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.7750 Acc: 16.6667\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.7815 Acc: 16.6859\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.7920 Acc: 16.7051\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.7972 Acc: 16.7244\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.8053 Acc: 16.7372\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.8186 Acc: 16.7436\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.8218 Acc: 16.7692\nTrain: Loss: 7.3463 Acc: 10.2869 Val: Loss: 11.8605 Acc: 16.7692\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.8775 Acc: 16.8077\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.8842 Acc: 16.8269\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.8904 Acc: 16.8397\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.8967 Acc: 16.8590\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.9068 Acc: 16.8782\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.9208 Acc: 16.8846\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.9292 Acc: 16.8910\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.9345 Acc: 16.9103\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.9363 Acc: 16.9359\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.9450 Acc: 16.9487\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.9508 Acc: 16.9679\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.9582 Acc: 16.9808\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.9609 Acc: 17.0064\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.9632 Acc: 17.0321\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.9820 Acc: 17.0385\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.9892 Acc: 17.0577\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 11.9950 Acc: 17.0769\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.0017 Acc: 17.0962\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.0068 Acc: 17.1154\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.0098 Acc: 17.1410\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.0173 Acc: 17.1603\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.0283 Acc: 17.1731\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.0380 Acc: 17.1859\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.0441 Acc: 17.2051\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.0497 Acc: 17.2244\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.0653 Acc: 17.2308\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.0766 Acc: 17.2436\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.0824 Acc: 17.2628\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.0895 Acc: 17.2821\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.1101 Acc: 17.2885\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.1260 Acc: 17.3013\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.1318 Acc: 17.3205\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.1454 Acc: 17.3333\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.1490 Acc: 17.3590\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.1516 Acc: 17.3846\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.1677 Acc: 17.4038\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.1712 Acc: 17.4295\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.1802 Acc: 17.4487\nTrain: Loss: 7.5896 Acc: 10.7336 Val: Loss: 12.1883 Acc: 17.4744\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.2008 Acc: 17.5192\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.2074 Acc: 17.5385\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.2130 Acc: 17.5577\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.2158 Acc: 17.5833\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.2221 Acc: 17.6090\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.2310 Acc: 17.6154\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.2346 Acc: 17.6346\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.2428 Acc: 17.6538\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.2533 Acc: 17.6731\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.2567 Acc: 17.6987\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.2792 Acc: 17.7051\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.2859 Acc: 17.7179\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.2930 Acc: 17.7372\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.2987 Acc: 17.7564\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.3087 Acc: 17.7756\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.3150 Acc: 17.7885\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.3200 Acc: 17.8077\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.3258 Acc: 17.8269\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.3341 Acc: 17.8397\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.3422 Acc: 17.8590\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.3465 Acc: 17.8782\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.3612 Acc: 17.8846\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.3640 Acc: 17.9103\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.3740 Acc: 17.9231\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.3777 Acc: 17.9423\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.3909 Acc: 17.9551\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.3936 Acc: 17.9808\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.4027 Acc: 17.9936\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.4077 Acc: 18.0128\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.4187 Acc: 18.0321\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.4246 Acc: 18.0513\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.4327 Acc: 18.0705\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.4399 Acc: 18.0897\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.4440 Acc: 18.1090\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.4484 Acc: 18.1282\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.4705 Acc: 18.1282\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.4793 Acc: 18.1474\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.4840 Acc: 18.1731\nTrain: Loss: 7.7986 Acc: 11.1844 Val: Loss: 12.5233 Acc: 18.1731\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.5369 Acc: 18.2179\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.5416 Acc: 18.2372\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.5485 Acc: 18.2564\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.5588 Acc: 18.2692\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.5609 Acc: 18.2949\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.5656 Acc: 18.3077\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.5664 Acc: 18.3333\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.5752 Acc: 18.3526\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.5886 Acc: 18.3590\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.5992 Acc: 18.3718\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.6048 Acc: 18.3846\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.6186 Acc: 18.3910\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.6380 Acc: 18.3910\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.6483 Acc: 18.4038\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.6518 Acc: 18.4231\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.6631 Acc: 18.4359\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.6703 Acc: 18.4551\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.6866 Acc: 18.4615\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.6909 Acc: 18.4872\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.7012 Acc: 18.5000\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.7145 Acc: 18.5064\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.7197 Acc: 18.5192\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.7246 Acc: 18.5385\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.7271 Acc: 18.5641\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.7289 Acc: 18.5897\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.7375 Acc: 18.6090\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.7403 Acc: 18.6346\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.7508 Acc: 18.6538\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.7584 Acc: 18.6731\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.7658 Acc: 18.6859\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.7692 Acc: 18.7115\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.7841 Acc: 18.7244\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.7931 Acc: 18.7436\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.8081 Acc: 18.7628\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.8096 Acc: 18.7885\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.8242 Acc: 18.8013\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.8285 Acc: 18.8269\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.8447 Acc: 18.8397\nTrain: Loss: 8.0140 Acc: 11.6311 Val: Loss: 12.8844 Acc: 18.8397\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 12.8983 Acc: 18.8782\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 12.9070 Acc: 18.8910\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 12.9131 Acc: 18.9167\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 12.9243 Acc: 18.9231\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 12.9284 Acc: 18.9423\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 12.9422 Acc: 18.9551\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 12.9548 Acc: 18.9679\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 12.9659 Acc: 18.9808\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 12.9724 Acc: 19.0000\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 12.9840 Acc: 19.0128\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 12.9942 Acc: 19.0256\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.0066 Acc: 19.0385\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.0150 Acc: 19.0577\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.0290 Acc: 19.0641\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.0401 Acc: 19.0769\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.0494 Acc: 19.0962\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.0619 Acc: 19.1154\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.0733 Acc: 19.1218\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.0747 Acc: 19.1474\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.0827 Acc: 19.1667\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.0936 Acc: 19.1795\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.0990 Acc: 19.1987\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.1152 Acc: 19.2115\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.1200 Acc: 19.2308\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.1262 Acc: 19.2500\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.1324 Acc: 19.2756\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.1542 Acc: 19.2885\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.1562 Acc: 19.3141\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.1579 Acc: 19.3397\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.1616 Acc: 19.3590\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.1632 Acc: 19.3846\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.1779 Acc: 19.3974\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.1804 Acc: 19.4167\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.1926 Acc: 19.4295\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.2152 Acc: 19.4423\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.2201 Acc: 19.4615\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.2373 Acc: 19.4744\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.2445 Acc: 19.4936\nTrain: Loss: 8.2434 Acc: 12.0533 Val: Loss: 13.2531 Acc: 19.5192\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.2649 Acc: 19.5577\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.2735 Acc: 19.5705\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.2748 Acc: 19.5962\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.2794 Acc: 19.6218\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.2919 Acc: 19.6410\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.2961 Acc: 19.6603\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.3057 Acc: 19.6795\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.3219 Acc: 19.6923\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.3249 Acc: 19.7179\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.3349 Acc: 19.7372\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.3406 Acc: 19.7564\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.3504 Acc: 19.7692\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.3630 Acc: 19.7756\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.3758 Acc: 19.7885\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.3845 Acc: 19.8013\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.3972 Acc: 19.8141\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.4231 Acc: 19.8141\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.4277 Acc: 19.8333\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.4395 Acc: 19.8526\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.4453 Acc: 19.8718\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.4527 Acc: 19.8910\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.4612 Acc: 19.9038\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.4658 Acc: 19.9231\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.4753 Acc: 19.9359\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.4855 Acc: 19.9487\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.4986 Acc: 19.9615\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.5033 Acc: 19.9872\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.5144 Acc: 20.0000\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.5195 Acc: 20.0192\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.5283 Acc: 20.0385\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.5329 Acc: 20.0641\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.5470 Acc: 20.0705\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.5585 Acc: 20.0833\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.5662 Acc: 20.1026\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.5814 Acc: 20.1154\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.5910 Acc: 20.1346\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.5949 Acc: 20.1603\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.6041 Acc: 20.1795\nTrain: Loss: 8.4777 Acc: 12.4918 Val: Loss: 13.6127 Acc: 20.2051\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.6266 Acc: 20.2436\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.6375 Acc: 20.2628\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.6473 Acc: 20.2756\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.6574 Acc: 20.2885\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.6664 Acc: 20.3077\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.6719 Acc: 20.3205\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.6788 Acc: 20.3333\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.6973 Acc: 20.3462\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.7021 Acc: 20.3654\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.7129 Acc: 20.3846\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.7255 Acc: 20.3910\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.7340 Acc: 20.4103\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.7451 Acc: 20.4231\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.7494 Acc: 20.4487\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.7595 Acc: 20.4615\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.7752 Acc: 20.4744\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.7858 Acc: 20.4808\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.7876 Acc: 20.5064\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.7894 Acc: 20.5321\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.8064 Acc: 20.5321\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.8143 Acc: 20.5449\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.8202 Acc: 20.5705\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.8250 Acc: 20.5897\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.8297 Acc: 20.6090\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.8314 Acc: 20.6346\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.8466 Acc: 20.6410\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.8542 Acc: 20.6603\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.8593 Acc: 20.6795\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.8672 Acc: 20.6923\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.8724 Acc: 20.7179\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.8756 Acc: 20.7436\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.8888 Acc: 20.7500\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.8938 Acc: 20.7756\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.9043 Acc: 20.7885\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.9077 Acc: 20.8141\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.9172 Acc: 20.8333\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.9229 Acc: 20.8590\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.9407 Acc: 20.8590\nTrain: Loss: 8.7038 Acc: 12.9344 Val: Loss: 13.9818 Acc: 20.8590\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.0105 Acc: 20.8782\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.0250 Acc: 20.8910\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.0388 Acc: 20.8974\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.0473 Acc: 20.9167\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.0539 Acc: 20.9295\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.0559 Acc: 20.9551\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.0614 Acc: 20.9744\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.0665 Acc: 21.0000\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.0736 Acc: 21.0192\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.0751 Acc: 21.0449\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.0837 Acc: 21.0641\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.1001 Acc: 21.0769\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.1085 Acc: 21.0897\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.1129 Acc: 21.1090\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.1326 Acc: 21.1154\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.1368 Acc: 21.1346\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.1427 Acc: 21.1603\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.1574 Acc: 21.1795\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.1613 Acc: 21.1987\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.1665 Acc: 21.2179\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.1707 Acc: 21.2436\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.1799 Acc: 21.2628\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.1893 Acc: 21.2756\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.1954 Acc: 21.2885\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.2029 Acc: 21.3013\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.2138 Acc: 21.3205\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.2219 Acc: 21.3269\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.2281 Acc: 21.3462\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.2361 Acc: 21.3654\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.2483 Acc: 21.3718\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.2508 Acc: 21.3910\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.2584 Acc: 21.4103\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.2742 Acc: 21.4231\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.2858 Acc: 21.4359\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.2936 Acc: 21.4551\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.3017 Acc: 21.4679\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.3135 Acc: 21.4808\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.3188 Acc: 21.5064\nTrain: Loss: 8.9493 Acc: 13.3443 Val: Loss: 14.3270 Acc: 21.5321\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.3543 Acc: 21.5577\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.3659 Acc: 21.5705\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.3716 Acc: 21.5897\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.3775 Acc: 21.6154\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.4061 Acc: 21.6154\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.4152 Acc: 21.6282\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.4244 Acc: 21.6410\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.4344 Acc: 21.6603\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.4504 Acc: 21.6731\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.4599 Acc: 21.6859\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.4723 Acc: 21.6987\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.4822 Acc: 21.7115\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.4868 Acc: 21.7372\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.4943 Acc: 21.7564\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.5002 Acc: 21.7756\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.5051 Acc: 21.8013\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.5118 Acc: 21.8205\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.5155 Acc: 21.8462\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.5236 Acc: 21.8590\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.5396 Acc: 21.8718\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.5493 Acc: 21.8846\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.5631 Acc: 21.8910\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.5637 Acc: 21.9167\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.5683 Acc: 21.9423\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.5705 Acc: 21.9679\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.5768 Acc: 21.9936\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.5844 Acc: 22.0128\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.5914 Acc: 22.0256\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.6046 Acc: 22.0385\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.6193 Acc: 22.0513\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.6231 Acc: 22.0705\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.6265 Acc: 22.0962\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.6358 Acc: 22.1026\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.6467 Acc: 22.1090\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.6495 Acc: 22.1346\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.6573 Acc: 22.1538\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.6627 Acc: 22.1731\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.6717 Acc: 22.1923\nTrain: Loss: 9.1661 Acc: 13.7787 Val: Loss: 14.6803 Acc: 22.2179\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.7022 Acc: 22.2436\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.7176 Acc: 22.2500\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.7232 Acc: 22.2692\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.7268 Acc: 22.2885\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.7348 Acc: 22.3013\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.7441 Acc: 22.3205\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.7494 Acc: 22.3462\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.7545 Acc: 22.3654\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.7645 Acc: 22.3718\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.7797 Acc: 22.3846\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.7844 Acc: 22.4103\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.7929 Acc: 22.4231\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.7988 Acc: 22.4423\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.8059 Acc: 22.4551\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.8111 Acc: 22.4808\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.8226 Acc: 22.4936\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.8418 Acc: 22.5064\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.8543 Acc: 22.5192\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.8592 Acc: 22.5385\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.8699 Acc: 22.5513\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.8807 Acc: 22.5705\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.8929 Acc: 22.5833\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.8983 Acc: 22.6090\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.9090 Acc: 22.6282\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.9178 Acc: 22.6410\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.9186 Acc: 22.6667\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.9245 Acc: 22.6859\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.9266 Acc: 22.7115\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.9365 Acc: 22.7308\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.9526 Acc: 22.7372\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.9567 Acc: 22.7628\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.9725 Acc: 22.7692\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.9842 Acc: 22.7756\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 14.9932 Acc: 22.7885\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 15.0006 Acc: 22.8077\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 15.0065 Acc: 22.8269\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 15.0133 Acc: 22.8526\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 15.0220 Acc: 22.8654\nTrain: Loss: 9.3890 Acc: 14.2172 Val: Loss: 15.0626 Acc: 22.8654\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.0946 Acc: 22.8910\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.1053 Acc: 22.8974\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.1081 Acc: 22.9167\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.1110 Acc: 22.9423\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.1203 Acc: 22.9551\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.1219 Acc: 22.9808\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.1286 Acc: 22.9936\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.1345 Acc: 23.0192\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.1422 Acc: 23.0385\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.1436 Acc: 23.0641\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.1541 Acc: 23.0833\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.1599 Acc: 23.1026\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.1672 Acc: 23.1218\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.1783 Acc: 23.1346\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.1952 Acc: 23.1474\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.2010 Acc: 23.1731\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.2078 Acc: 23.1923\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.2118 Acc: 23.2115\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.2167 Acc: 23.2308\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.2278 Acc: 23.2436\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.2361 Acc: 23.2564\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.2486 Acc: 23.2692\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.2509 Acc: 23.2949\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.2630 Acc: 23.3077\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.2683 Acc: 23.3269\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.2759 Acc: 23.3462\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.2842 Acc: 23.3590\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.2987 Acc: 23.3782\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.3041 Acc: 23.4038\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.3160 Acc: 23.4167\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.3264 Acc: 23.4359\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.3333 Acc: 23.4551\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.3409 Acc: 23.4744\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.3455 Acc: 23.4936\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.3498 Acc: 23.5192\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.3675 Acc: 23.5321\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.3817 Acc: 23.5449\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.3875 Acc: 23.5705\nTrain: Loss: 9.6400 Acc: 14.6270 Val: Loss: 15.3961 Acc: 23.5962\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.4120 Acc: 23.6218\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.4186 Acc: 23.6410\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.4279 Acc: 23.6603\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.4302 Acc: 23.6859\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.4420 Acc: 23.6987\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.4539 Acc: 23.7115\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.4678 Acc: 23.7179\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.4706 Acc: 23.7436\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.4771 Acc: 23.7628\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.4838 Acc: 23.7821\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.4900 Acc: 23.8013\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.5001 Acc: 23.8077\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.5130 Acc: 23.8141\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.5198 Acc: 23.8333\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.5218 Acc: 23.8526\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.5341 Acc: 23.8590\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.5423 Acc: 23.8782\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.5445 Acc: 23.9038\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.5575 Acc: 23.9167\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.5637 Acc: 23.9359\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.5666 Acc: 23.9551\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.5818 Acc: 23.9615\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.5972 Acc: 23.9744\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.6174 Acc: 23.9872\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.6258 Acc: 24.0064\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.6302 Acc: 24.0321\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.6332 Acc: 24.0577\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.6356 Acc: 24.0833\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.6476 Acc: 24.0962\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.6564 Acc: 24.1154\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.6603 Acc: 24.1346\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.6646 Acc: 24.1603\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.6694 Acc: 24.1795\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.6722 Acc: 24.2051\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.6788 Acc: 24.2244\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.6878 Acc: 24.2372\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.6905 Acc: 24.2628\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.6960 Acc: 24.2821\nTrain: Loss: 9.8490 Acc: 15.0902 Val: Loss: 15.7350 Acc: 24.2821\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.7494 Acc: 24.3205\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.7538 Acc: 24.3462\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.7567 Acc: 24.3718\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.7635 Acc: 24.3910\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.7825 Acc: 24.3974\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.7934 Acc: 24.4038\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.8005 Acc: 24.4231\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.8063 Acc: 24.4487\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.8084 Acc: 24.4744\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.8139 Acc: 24.4936\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.8234 Acc: 24.5128\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.8265 Acc: 24.5385\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.8369 Acc: 24.5513\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.8399 Acc: 24.5705\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.8447 Acc: 24.5897\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.8578 Acc: 24.6026\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.8592 Acc: 24.6282\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.8698 Acc: 24.6474\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.8750 Acc: 24.6667\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.8817 Acc: 24.6795\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.8907 Acc: 24.6987\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.9015 Acc: 24.7115\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.9065 Acc: 24.7308\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.9115 Acc: 24.7500\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.9190 Acc: 24.7628\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.9293 Acc: 24.7756\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.9435 Acc: 24.7885\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.9479 Acc: 24.8077\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.9519 Acc: 24.8269\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.9705 Acc: 24.8333\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.9769 Acc: 24.8526\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 15.9904 Acc: 24.8654\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 16.0068 Acc: 24.8782\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 16.0098 Acc: 24.9038\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 16.0154 Acc: 24.9231\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 16.0216 Acc: 24.9423\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 16.0237 Acc: 24.9679\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 16.0273 Acc: 24.9936\nTrain: Loss: 10.0642 Acc: 15.5369 Val: Loss: 16.0364 Acc: 25.0192\nTrain: Loss: 10.2590 Acc: 16.0041 Val: Loss: 16.0632 Acc: 25.0385\nTrain: Loss: 10.2590 Acc: 16.0041 Val: Loss: 16.0692 Acc: 25.0641\nTrain: Loss: 10.2590 Acc: 16.0041 Val: Loss: 16.0765 Acc: 25.0833\nTrain: Loss: 10.2590 Acc: 16.0041 Val: Loss: 16.0926 Acc: 25.0962\nTrain: Loss: 10.2590 Acc: 16.0041 Val: Loss: 16.1007 Acc: 25.1154\nTrain: Loss: 10.2590 Acc: 16.0041 Val: Loss: 16.1061 Acc: 25.1410\nTrain: Loss: 10.2590 Acc: 16.0041 Val: Loss: 16.1170 Acc: 25.1603\nTrain: Loss: 10.2590 Acc: 16.0041 Val: Loss: 16.1199 Acc: 25.1859\nTrain: Loss: 10.2590 Acc: 16.0041 Val: Loss: 16.1318 Acc: 25.2051\nTrain: Loss: 10.2590 Acc: 16.0041 Val: Loss: 16.1397 Acc: 25.2244\nTrain: Loss: 10.2590 Acc: 16.0041 Val: Loss: 16.1508 Acc: 25.2372\nTrain: Loss: 10.2590 Acc: 16.0041 Val: Loss: 16.1590 Acc: 25.2500\nTrain: Loss: 10.2590 Acc: 16.0041 Val: Loss: 16.1719 Acc: 25.2564\nTrain: Loss: 10.2590 Acc: 16.0041 Val: Loss: 16.1853 Acc: 25.2628\nTrain: Loss: 10.2590 Acc: 16.0041 Val: Loss: 16.1963 Acc: 25.2756\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[39], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m train_epoch_acc \u001b[38;5;241m=\u001b[39m running_corrects \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[0;32m---> 35\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     37\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}