{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aleksandrmorozov123/deep-learning-for-nlp?scriptVersionId=156326010\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"1c0dc1df","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-24T16:08:10.421616Z","iopub.status.busy":"2023-12-24T16:08:10.420762Z","iopub.status.idle":"2023-12-24T16:08:11.440618Z","shell.execute_reply":"2023-12-24T16:08:11.439215Z"},"papermill":{"duration":1.029836,"end_time":"2023-12-24T16:08:11.443311","exception":false,"start_time":"2023-12-24T16:08:10.413475","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","id":"1a0ab57e","metadata":{"papermill":{"duration":0.004234,"end_time":"2023-12-24T16:08:11.454998","exception":false,"start_time":"2023-12-24T16:08:11.450764","status":"completed"},"tags":[]},"source":["**Checking statistics of the Corpus**"]},{"cell_type":"code","execution_count":2,"id":"98556308","metadata":{"execution":{"iopub.execute_input":"2023-12-24T16:08:11.467004Z","iopub.status.busy":"2023-12-24T16:08:11.465922Z","iopub.status.idle":"2023-12-24T16:08:13.23858Z","shell.execute_reply":"2023-12-24T16:08:13.230752Z"},"papermill":{"duration":1.786033,"end_time":"2023-12-24T16:08:13.245542","exception":false,"start_time":"2023-12-24T16:08:11.459509","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 50000 entries, 0 to 49999\n","Data columns (total 2 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   review     50000 non-null  object\n"," 1   sentiment  50000 non-null  object\n","dtypes: object(2)\n","memory usage: 781.4+ KB\n"]}],"source":["# import required libraries\n","import pandas as pd\n","reviews = pd.read_csv ('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n","reviews.info()"]},{"cell_type":"code","execution_count":3,"id":"8e0d98f0","metadata":{"execution":{"iopub.execute_input":"2023-12-24T16:08:13.26075Z","iopub.status.busy":"2023-12-24T16:08:13.258954Z","iopub.status.idle":"2023-12-24T16:08:13.270623Z","shell.execute_reply":"2023-12-24T16:08:13.268874Z"},"papermill":{"duration":0.024062,"end_time":"2023-12-24T16:08:13.276155","exception":false,"start_time":"2023-12-24T16:08:13.252093","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["'The first time I saw this \"film\" I loved it. When I was 11, I was more interested in the music and dancing. As I\\'ve grown older, I\\'ve become more interested in the acting as well. While the first half is just a retrospective of Michael\\'s career (from the Jackson 5 up to \"Bad\"), it was still entertai'\n","'...now please move on because that\\'s getting on my nerves.<br /><br />Seriously, the man behind brilliant pieces like \"My Own Private Idaho\" and \"To Die For\" (and others not so brilliant movies, i.e. the unnecessary \"Psycho\" remake) started an experimental phase with \"Gerry\", which reached its peak '\n"]}],"source":["# comparing the text of two selected reviews\n","print (repr(reviews.iloc[3344]['review'][0:300]))\n","print (repr(reviews.iloc[23909]['review'][0:300]))"]},{"cell_type":"code","execution_count":4,"id":"77c5f015","metadata":{"execution":{"iopub.execute_input":"2023-12-24T16:08:13.288852Z","iopub.status.busy":"2023-12-24T16:08:13.287931Z","iopub.status.idle":"2023-12-24T16:08:14.693868Z","shell.execute_reply":"2023-12-24T16:08:14.692387Z"},"papermill":{"duration":1.41664,"end_time":"2023-12-24T16:08:14.69779","exception":false,"start_time":"2023-12-24T16:08:13.28115","status":"completed"},"tags":[]},"outputs":[],"source":["# ignore spaces after the stop words\n","import re\n","reviews [\"paragraphs\"] = reviews [\"review\"].map (lambda text: re.split ('[.?!]\\s*\\n', text))\n","reviews ['number_of_paragraphs'] = reviews [\"paragraphs\"].map (len)"]},{"cell_type":"markdown","id":"cdc0c90c","metadata":{"papermill":{"duration":0.004635,"end_time":"2023-12-24T16:08:14.707599","exception":false,"start_time":"2023-12-24T16:08:14.702964","status":"completed"},"tags":[]},"source":["**Preparations**"]},{"cell_type":"code","execution_count":5,"id":"9b5d9bda","metadata":{"execution":{"iopub.execute_input":"2023-12-24T16:08:14.719662Z","iopub.status.busy":"2023-12-24T16:08:14.719111Z","iopub.status.idle":"2023-12-24T16:08:39.97878Z","shell.execute_reply":"2023-12-24T16:08:39.977149Z"},"papermill":{"duration":25.269308,"end_time":"2023-12-24T16:08:39.981782","exception":false,"start_time":"2023-12-24T16:08:14.712474","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(50000, 101758)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# import required libraries\n","import sklearn\n","import spacy\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from spacy.lang.de.stop_words import STOP_WORDS\n","\n","tfidf_text_vectorizer = TfidfVectorizer(stop_words=list(STOP_WORDS))\n","vectors_text = tfidf_text_vectorizer.fit_transform (reviews ['review'])\n","vectors_text.shape"]},{"cell_type":"code","execution_count":6,"id":"380c1e7c","metadata":{"execution":{"iopub.execute_input":"2023-12-24T16:08:39.994628Z","iopub.status.busy":"2023-12-24T16:08:39.993473Z","iopub.status.idle":"2023-12-24T16:08:57.368078Z","shell.execute_reply":"2023-12-24T16:08:57.366533Z"},"papermill":{"duration":17.384326,"end_time":"2023-12-24T16:08:57.371068","exception":false,"start_time":"2023-12-24T16:08:39.986742","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(50000, 101758)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# flatten the paragraphs keeping the sentiment\n","paragraph_df = pd.DataFrame ([{'review': paragraph, 'sentiment': sentiment}\n","                             for paragraphs, sentiment in \\\n","                             zip (reviews ['paragraphs'], reviews ['sentiment'])\n","                             for paragraph in paragraphs if paragraph])\n","tfidf_para_vectorizer = TfidfVectorizer(stop_words=list(STOP_WORDS))\n","tfidf_para_vectors = tfidf_para_vectorizer.fit_transform (paragraph_df ['review'])\n","tfidf_para_vectors.shape"]},{"cell_type":"markdown","id":"a519aaa5","metadata":{"papermill":{"duration":0.004618,"end_time":"2023-12-24T16:08:57.380726","exception":false,"start_time":"2023-12-24T16:08:57.376108","status":"completed"},"tags":[]},"source":["**Nonnegative matrix factorization** - $ V \\approx W \\cdot H $"]},{"cell_type":"code","execution_count":7,"id":"85f560f7","metadata":{"execution":{"iopub.execute_input":"2023-12-24T16:08:57.393961Z","iopub.status.busy":"2023-12-24T16:08:57.393412Z","iopub.status.idle":"2023-12-24T16:09:53.788535Z","shell.execute_reply":"2023-12-24T16:09:53.785736Z"},"papermill":{"duration":56.405601,"end_time":"2023-12-24T16:09:53.791969","exception":false,"start_time":"2023-12-24T16:08:57.386368","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\n","topic 00\n","  the (8.01)\n","  of (1.84)\n","  to (0.47)\n","  from (0.43)\n","  on (0.41)\n","\n","topic 01\n","  br (22.11)\n","  10 (0.50)\n","  some (0.26)\n","  no (0.25)\n","  here (0.24)\n","\n","topic 02\n","  to (2.22)\n","  they (1.33)\n","  that (1.24)\n","  have (0.75)\n","  show (0.73)\n","\n","topic 03\n","  he (2.65)\n","  his (2.18)\n","  to (0.96)\n","  him (0.92)\n","  the (0.89)\n","\n","topic 04\n","  film (4.47)\n","  is (2.06)\n","  this (1.92)\n","  films (0.97)\n","  to (0.96)\n","\n","topic 05\n","  movie (6.44)\n","  this (3.26)\n","  is (1.94)\n","  bad (1.40)\n","  movies (1.32)\n","\n","topic 06\n","  and (3.04)\n","  of (1.22)\n","  is (1.17)\n","  are (0.60)\n","  as (0.60)\n","\n","topic 07\n","  you (6.92)\n","  if (2.34)\n","  your (1.59)\n","  don (0.90)\n","  watch (0.88)\n","\n","topic 08\n","  she (4.31)\n","  is (1.02)\n","  the (0.79)\n","  to (0.76)\n","  and (0.56)\n","\n","topic 09\n","  it (6.17)\n","  and (1.74)\n","  but (1.19)\n","  my (1.07)\n","  the (0.97)\n"]}],"source":["# import required library\n","from sklearn.decomposition import NMF\n","\n","nmf_text_model = NMF (n_components = 10, random_state = 42)\n","W_text_matrix = nmf_text_model.fit_transform (vectors_text)\n","H_text_matrix = nmf_text_model.components_\n","\n","# define a function for outputtin a summary\n","def display_topics (model, features, no_top_words=5):\n","    for topic, word_vector in enumerate (nmf_text_model.components_):\n","        total = word_vector.sum ()\n","        largest = word_vector.argsort ()[::-1]  # invert sort order\n","        print (\"\\ntopic %02d\" % topic)\n","        for i in range (0, no_top_words):\n","            print (\"  %s (%2.2f)\" % (features [largest [i]],\n","                                    word_vector [largest[i]] * 100.0/total))\n","            \n","# calling the function\n","display_topics (nmf_text_model, tfidf_text_vectorizer.get_feature_names_out())"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":134715,"sourceId":320111,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":109.237768,"end_time":"2023-12-24T16:09:55.428005","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-12-24T16:08:06.190237","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}