{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4856154,"sourceType":"datasetVersion","datasetId":2815070}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aleksandrmorozov123/transformers?scriptVersionId=232777589\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-08T04:06:36.569085Z","iopub.execute_input":"2025-04-08T04:06:36.569427Z","iopub.status.idle":"2025-04-08T04:06:38.292083Z","shell.execute_reply.started":"2025-04-08T04:06:36.569385Z","shell.execute_reply":"2025-04-08T04:06:38.290938Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Self-attention mechanizm is a foundational block of all transformer architectures**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.nn.functional import softmax","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T03:44:14.267391Z","iopub.execute_input":"2025-04-09T03:44:14.267615Z","iopub.status.idle":"2025-04-09T03:44:18.022183Z","shell.execute_reply.started":"2025-04-09T03:44:14.267593Z","shell.execute_reply":"2025-04-09T03:44:18.021275Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# we start with 3 inputs, each with dimension 4\nx = [\n    [1, 0, 2, 0],\n    [0, 3, 0, 3],\n    [2, 2, 2, 2]\n]\n\nx = torch.tensor (x, dtype = torch.float32)\nx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T03:44:20.014312Z","iopub.execute_input":"2025-04-09T03:44:20.014666Z","iopub.status.idle":"2025-04-09T03:44:20.106462Z","shell.execute_reply.started":"2025-04-09T03:44:20.014636Z","shell.execute_reply":"2025-04-09T03:44:20.105481Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"tensor([[1., 0., 2., 0.],\n        [0., 3., 0., 3.],\n        [2., 2., 2., 2.]])"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# initialise weights\nw_key = [\n    [0, 1, 1],\n    [2, 1, 0],\n    [1, 0, 1],\n    [3, 3, 1]\n]\nw_query = [\n    [1, 0, 1],\n    [2, 0, 3],\n    [0, 2, 3],\n    [0, 2, 2]\n]\nw_value = [\n    [0, 2, 1],\n    [0, 2, 0],\n    [1, 3, 0],\n    [2, 2, 0]\n]\n\nw_key = torch.tensor (w_key, dtype = torch.float32)\nw_query = torch.tensor (w_query, dtype = torch.float32)\nw_value = torch.tensor (w_value, dtype = torch.float32)\n\nprint (\"Weights for key: \\n\", w_key)\nprint (\"Weights for query: \\n\", w_query)\nprint (\"Weights for value: \\n\", w_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T03:44:22.0233Z","iopub.execute_input":"2025-04-09T03:44:22.023775Z","iopub.status.idle":"2025-04-09T03:44:22.034761Z","shell.execute_reply.started":"2025-04-09T03:44:22.023734Z","shell.execute_reply":"2025-04-09T03:44:22.033836Z"}},"outputs":[{"name":"stdout","text":"Weights for key: \n tensor([[0., 1., 1.],\n        [2., 1., 0.],\n        [1., 0., 1.],\n        [3., 3., 1.]])\nWeights for query: \n tensor([[1., 0., 1.],\n        [2., 0., 3.],\n        [0., 2., 3.],\n        [0., 2., 2.]])\nWeights for value: \n tensor([[0., 2., 1.],\n        [0., 2., 0.],\n        [1., 3., 0.],\n        [2., 2., 0.]])\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# adding the bias vector to the product of matrix multiplication\nkeys = x @ w_key\nquerys = x @ w_query\nvalues = x @ w_value\n\nprint (\"Keys: \\n\", keys)\nprint (\"Querys: \\n\", querys)\nprint (\"Values: \\n\", values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T03:44:25.543887Z","iopub.execute_input":"2025-04-09T03:44:25.544301Z","iopub.status.idle":"2025-04-09T03:44:25.572538Z","shell.execute_reply.started":"2025-04-09T03:44:25.544269Z","shell.execute_reply":"2025-04-09T03:44:25.571506Z"}},"outputs":[{"name":"stdout","text":"Keys: \n tensor([[ 2.,  1.,  3.],\n        [15., 12.,  3.],\n        [12., 10.,  6.]])\nQuerys: \n tensor([[ 1.,  4.,  7.],\n        [ 6.,  6., 15.],\n        [ 6.,  8., 18.]])\nValues: \n tensor([[ 2.,  8.,  1.],\n        [ 6., 12.,  0.],\n        [ 6., 18.,  2.]])\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# calculating attention scores\nattn_scores = querys @ keys.T\nprint (attn_scores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T03:44:27.989487Z","iopub.execute_input":"2025-04-09T03:44:27.989858Z","iopub.status.idle":"2025-04-09T03:44:27.997135Z","shell.execute_reply.started":"2025-04-09T03:44:27.989828Z","shell.execute_reply":"2025-04-09T03:44:27.996202Z"}},"outputs":[{"name":"stdout","text":"tensor([[ 27.,  84.,  94.],\n        [ 63., 207., 222.],\n        [ 74., 240., 260.]])\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# calculate softmax\nattn_scores_softmax = softmax (attn_scores, dim = -1)\n\nprint (attn_scores_softmax)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T03:44:30.393584Z","iopub.execute_input":"2025-04-09T03:44:30.393938Z","iopub.status.idle":"2025-04-09T03:44:30.403238Z","shell.execute_reply.started":"2025-04-09T03:44:30.393912Z","shell.execute_reply":"2025-04-09T03:44:30.402229Z"}},"outputs":[{"name":"stdout","text":"tensor([[7.9845e-30, 4.5398e-05, 9.9995e-01],\n        [0.0000e+00, 3.0590e-07, 1.0000e+00],\n        [0.0000e+00, 2.0612e-09, 1.0000e+00]])\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"attn_scores_softmax = [\n    [0.0, 0.5, 0.5],\n    [0.0, 1.0, 0.0],\n    [0.0, 0.9, 0.1]\n]\nattn_scores_softmax = torch.tensor (attn_scores_softmax)\n\nprint (attn_scores_softmax)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T03:44:31.811943Z","iopub.execute_input":"2025-04-09T03:44:31.812316Z","iopub.status.idle":"2025-04-09T03:44:31.819072Z","shell.execute_reply.started":"2025-04-09T03:44:31.812286Z","shell.execute_reply":"2025-04-09T03:44:31.817857Z"}},"outputs":[{"name":"stdout","text":"tensor([[0.0000, 0.5000, 0.5000],\n        [0.0000, 1.0000, 0.0000],\n        [0.0000, 0.9000, 0.1000]])\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# multiply scores with values\nweighted_values = values[:, None] * attn_scores_softmax.T[:,:, None]\nprint (weighted_values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T03:44:34.037293Z","iopub.execute_input":"2025-04-09T03:44:34.037669Z","iopub.status.idle":"2025-04-09T03:44:34.053619Z","shell.execute_reply.started":"2025-04-09T03:44:34.037637Z","shell.execute_reply":"2025-04-09T03:44:34.052756Z"}},"outputs":[{"name":"stdout","text":"tensor([[[ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000]],\n\n        [[ 3.0000,  6.0000,  0.0000],\n         [ 6.0000, 12.0000,  0.0000],\n         [ 5.4000, 10.8000,  0.0000]],\n\n        [[ 3.0000,  9.0000,  1.0000],\n         [ 0.0000,  0.0000,  0.0000],\n         [ 0.6000,  1.8000,  0.2000]]])\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# multiply scores with values of input 2 and input 3\noutputs = weighted_values.sum (dim = 0)\nprint (outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T03:44:36.955476Z","iopub.execute_input":"2025-04-09T03:44:36.955884Z","iopub.status.idle":"2025-04-09T03:44:36.963738Z","shell.execute_reply.started":"2025-04-09T03:44:36.95583Z","shell.execute_reply":"2025-04-09T03:44:36.962589Z"}},"outputs":[{"name":"stdout","text":"tensor([[ 6.0000, 15.0000,  1.0000],\n        [ 6.0000, 12.0000,  0.0000],\n        [ 6.0000, 12.6000,  0.2000]])\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"**Stable diffusion with Keras**","metadata":{}},{"cell_type":"code","source":"try:\n  import tensorflow as tf\n  print(tf.__version__)\nexcept:\n  !pip install tensorflow\n  import tensorflow as tf\n  print(tf.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T04:21:03.985737Z","iopub.execute_input":"2025-04-09T04:21:03.986165Z","iopub.status.idle":"2025-04-09T04:21:23.005917Z","shell.execute_reply.started":"2025-04-09T04:21:03.986132Z","shell.execute_reply":"2025-04-09T04:21:23.00421Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\nRequirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\nRequirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-b068e5ec29ce>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'Word2Vec' object is not callable","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-b068e5ec29ce>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install tensorflow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'Word2Vec' object is not callable"],"ename":"TypeError","evalue":"'Word2Vec' object is not callable","output_type":"error"}],"execution_count":24},{"cell_type":"code","source":"!pip install keras_cv --upgrade --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T04:21:48.900689Z","iopub.execute_input":"2025-04-09T04:21:48.90113Z","iopub.status.idle":"2025-04-09T04:21:53.34068Z","shell.execute_reply.started":"2025-04-09T04:21:48.901096Z","shell.execute_reply":"2025-04-09T04:21:53.339263Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"!pip install keras_core --upgrade --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T04:21:56.940117Z","iopub.execute_input":"2025-04-09T04:21:56.940495Z","iopub.status.idle":"2025-04-09T04:22:01.248736Z","shell.execute_reply.started":"2025-04-09T04:21:56.940462Z","shell.execute_reply":"2025-04-09T04:22:01.247129Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"import time\nimport keras_cv\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T04:22:04.609103Z","iopub.execute_input":"2025-04-09T04:22:04.60951Z","iopub.status.idle":"2025-04-09T04:22:07.731153Z","shell.execute_reply.started":"2025-04-09T04:22:04.609475Z","shell.execute_reply":"2025-04-09T04:22:07.730177Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"model = keras_cv.models.StableDiffusion(img_width=512, img_height=512)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T04:22:59.900688Z","iopub.execute_input":"2025-04-09T04:22:59.901112Z","iopub.status.idle":"2025-04-09T04:22:59.906899Z","shell.execute_reply.started":"2025-04-09T04:22:59.901081Z","shell.execute_reply":"2025-04-09T04:22:59.905821Z"}},"outputs":[{"name":"stdout","text":"By using this model checkpoint, you acknowledge that its usage is subject to the terms of the CreativeML Open RAIL-M license at https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# generating image with a prompt\nimages = model.text_to_image(\"sunset in a snow world\", batch_size=3)\n\n\ndef plot_images(images):\n    plt.figure(figsize=(20, 20))\n    for i in range(len(images)):\n        ax = plt.subplot(1, len(images), i + 1)\n        plt.imshow(images[i])\n        plt.axis(\"off\")\n\n\nplot_images(images)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T04:23:16.677487Z","iopub.execute_input":"2025-04-09T04:23:16.677886Z","iopub.status.idle":"2025-04-09T04:23:18.304537Z","shell.execute_reply.started":"2025-04-09T04:23:16.677854Z","shell.execute_reply":"2025-04-09T04:23:18.303022Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://github.com/openai/CLIP/blob/main/clip/bpe_simple_vocab_16e6.txt.gz?raw=true\n\u001b[1m1356917/1356917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-429102d0354b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# generating image with a prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sunset in a snow world\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_cv/src/models/stable_diffusion/stable_diffusion.py\u001b[0m in \u001b[0;36mtext_to_image\u001b[0;34m(self, prompt, negative_prompt, batch_size, num_steps, unconditional_guidance_scale, seed)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     ):\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mencoded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         return self.generate_image(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_cv/src/models/stable_diffusion/stable_diffusion.py\u001b[0m in \u001b[0;36mencode_text\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mphrase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         context = self.text_encoder.predict_on_batch(\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"positions\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_pos_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_cv/src/models/stable_diffusion/stable_diffusion.py\u001b[0m in \u001b[0;36mtext_encoder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \"\"\"\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text_encoder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_PROMPT_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjit_compile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_cv/src/models/stable_diffusion/text_encoder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, max_length, vocab_size, name, download_weights)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLIPEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLIPEncoderLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m768\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquick_gelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_cv/src/models/stable_diffusion/text_encoder.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_cv/src/models/stable_diffusion/text_encoder.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, attention_mask)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcausal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             attention_mask = ops.triu(\n\u001b[0m\u001b[1;32m    137\u001b[0m                 \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling CLIPEncoderLayer.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'clip_encoder_layer' (of type CLIPEncoderLayer). Either the `CLIPEncoderLayer.call()` method is incorrect, or you need to implement the `CLIPEncoderLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling CLIPAttention.call().\n\n\u001b[1mpred must not be a Python bool\u001b[0m\n\nArguments received by CLIPAttention.call():\n  • inputs=tf.Tensor(shape=(None, 77, 768), dtype=float32)\n  • attention_mask=None\u001b[0m\n\nArguments received by CLIPEncoderLayer.call():\n  • args=('<KerasTensor shape=(None, 77, 768), dtype=float32, sparse=False, name=keras_tensor_1>',)\n  • kwargs=<class 'inspect._empty'>"],"ename":"TypeError","evalue":"Exception encountered when calling CLIPEncoderLayer.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'clip_encoder_layer' (of type CLIPEncoderLayer). Either the `CLIPEncoderLayer.call()` method is incorrect, or you need to implement the `CLIPEncoderLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling CLIPAttention.call().\n\n\u001b[1mpred must not be a Python bool\u001b[0m\n\nArguments received by CLIPAttention.call():\n  • inputs=tf.Tensor(shape=(None, 77, 768), dtype=float32)\n  • attention_mask=None\u001b[0m\n\nArguments received by CLIPEncoderLayer.call():\n  • args=('<KerasTensor shape=(None, 77, 768), dtype=float32, sparse=False, name=keras_tensor_1>',)\n  • kwargs=<class 'inspect._empty'>","output_type":"error"}],"execution_count":30}]}